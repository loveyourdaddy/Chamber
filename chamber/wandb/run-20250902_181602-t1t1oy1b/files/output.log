self.seed = 42
[34m[1mwandb[0m: wandb.init() called while a run is active and reinit is set to 'default', so returning the previous run.
Started to train
/home/inseo/_chamber/chamber/chamber/tasks/ase_humanoid_base/humanoid.py:355: DeprecationWarning: an integer is required (got type isaacgym._bindings.linux-x86_64.gym_38.DofDriveMode).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  asset_options.default_dof_drive_mode = gymapi.DOF_MODE_NONE
Loading 1/1 motion files: tasks/data/motions/reallusion_sword_shield/RL_Avatar_Atk_2xCombo01_Motion.npy
Error for key= global_root_yaw_rotation
Error for key= global_translation_xy
Error for key= global_translation_xz
Error for key= local_rotation_to_root
Error for key= local_translation_to_root
Error for key= root_translation_xy
Total added 17
Loaded 1 motions with a total length of 3.175s.
Loading 1/1 motion files: tasks/data/motions/reallusion_sword_shield/RL_Avatar_Atk_2xCombo01_Motion.npy
Error for key= global_root_yaw_rotation
Error for key= global_translation_xy
Error for key= global_translation_xz
Error for key= local_rotation_to_root
Error for key= local_translation_to_root
Error for key= root_translation_xy
Total added 17
Loaded 1 motions with a total length of 3.175s.
RL device:  cuda:0
Box(-1.0, 1.0, (31,), float32) Box(-inf, inf, (330,), float32)
current training device: cuda:0
build mlp: 330
build mlp: 330
sigma
actor_mlp.0.weight
actor_mlp.0.bias
actor_mlp.2.weight
actor_mlp.2.bias
critic_mlp.0.weight
critic_mlp.0.bias
critic_mlp.2.weight
critic_mlp.2.bias
value.weight
value.bias
mu.weight
mu.bias
RunningMeanStd:  (1,)
RunningMeanStd:  (330,)
RunningMeanStd:  (330,)
current training device: cuda:0
[34m[1mwandb[0m: [33mWARNING[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
build amp style cat net: 253 64
build amp mlp net: 317
build mlp: 1400
sigma
actor_mlp._style_mlp.0.weight
actor_mlp._style_mlp.0.bias
actor_mlp._style_mlp.2.weight
actor_mlp._style_mlp.2.bias
actor_mlp._style_dense.weight
actor_mlp._style_dense.bias
actor_mlp._dense_layers.0.weight
actor_mlp._dense_layers.0.bias
actor_mlp._dense_layers.1.weight
actor_mlp._dense_layers.1.bias
actor_mlp._dense_layers.2.weight
actor_mlp._dense_layers.2.bias
critic_mlp._mlp.0.weight
critic_mlp._mlp.0.bias
critic_mlp._mlp.2.weight
critic_mlp._mlp.2.bias
critic_mlp._mlp.4.weight
critic_mlp._mlp.4.bias
value.weight
value.bias
mu.weight
mu.bias
_disc_mlp.0.weight
_disc_mlp.0.bias
_disc_mlp.2.weight
_disc_mlp.2.bias
_disc_mlp.4.weight
_disc_mlp.4.bias
_disc_logits.weight
_disc_logits.bias
_enc.weight
_enc.bias
RunningMeanStd:  (1,)
RunningMeanStd:  (253,)
RunningMeanStd:  (253,)
RunningMeanStd:  (1400,)
=> loading checkpoint 'tasks/data/models/llc_reallusion_sword_shield.pth'
/home/inseo/_chamber/chamber/chamber/utils/utils.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return func(*args, **kwargs)
Loaded LLC checkpoint from tasks/data/models/llc_reallusion_sword_shield.pth
build mlp: 330
build mlp: 330
sigma
actor_mlp.0.weight
actor_mlp.0.bias
actor_mlp.2.weight
actor_mlp.2.bias
critic_mlp.0.weight
critic_mlp.0.bias
critic_mlp.2.weight
critic_mlp.2.bias
value.weight
value.bias
mu.weight
mu.bias
RunningMeanStd:  (1,)
RunningMeanStd:  (330,)
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
/home/inseo/_chamber/chamber/chamber/ase/utils/common_agent.py:424: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=self.mixed_precision):
a_loss 0.373 c_loss 1.328 b_loss 0.000
a_loss 0.329 c_loss 1.277 b_loss 0.000
a_loss 0.316 c_loss 1.228 b_loss 0.000
a_loss 0.310 c_loss 1.181 b_loss 0.000
a_loss 0.307 c_loss 1.135 b_loss 0.000
a_loss 0.305 c_loss 1.092 b_loss 0.000
epoch num: 1
fps step: 1403 fps step and policy inference: 1321 fps total: 1304 epoch: 1/100000
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.891 c_loss 0.042 b_loss 0.000
a_loss 0.900 c_loss 0.048 b_loss 0.000
a_loss 0.903 c_loss 0.055 b_loss 0.000
a_loss 0.899 c_loss 0.060 b_loss 0.000
a_loss 0.892 c_loss 0.065 b_loss 0.000
a_loss 0.883 c_loss 0.069 b_loss 0.000
epoch num: 2
fps step: 1431 fps step and policy inference: 1375 fps total: 1365 epoch: 2/100000
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.098 b_loss 0.000
a_loss 0.894 c_loss 0.100 b_loss 0.000
a_loss 0.886 c_loss 0.101 b_loss 0.000
a_loss 0.879 c_loss 0.100 b_loss 0.000
a_loss 0.870 c_loss 0.098 b_loss 0.000
a_loss 0.861 c_loss 0.095 b_loss 0.000
epoch num: 3
fps step: 1498 fps step and policy inference: 1438 fps total: 1427 epoch: 3/100000
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.094 b_loss 0.000
a_loss 0.896 c_loss 0.089 b_loss 0.000
a_loss 0.885 c_loss 0.084 b_loss 0.000
a_loss 0.874 c_loss 0.079 b_loss 0.000
a_loss 0.862 c_loss 0.073 b_loss 0.000
a_loss 0.851 c_loss 0.067 b_loss 0.000
epoch num: 4
fps step: 1464 fps step and policy inference: 1394 fps total: 1384 epoch: 4/100000
epoch: 4 mean_rewards: [213.44] mean_lengths: 225.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.856 c_loss 0.051 b_loss 0.000
a_loss 0.849 c_loss 0.045 b_loss 0.000
a_loss 0.839 c_loss 0.041 b_loss 0.000
a_loss 0.828 c_loss 0.036 b_loss 0.000
a_loss 0.817 c_loss 0.032 b_loss 0.000
a_loss 0.806 c_loss 0.027 b_loss 0.000
epoch num: 5
fps step: 1492 fps step and policy inference: 1430 fps total: 1419 epoch: 5/100000
epoch: 5 mean_rewards: [287.72] mean_lengths: 300.00003
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.908 c_loss 0.036 b_loss 0.000
a_loss 0.899 c_loss 0.032 b_loss 0.000
a_loss 0.889 c_loss 0.028 b_loss 0.000
a_loss 0.879 c_loss 0.024 b_loss 0.000
a_loss 0.867 c_loss 0.021 b_loss 0.000
a_loss 0.855 c_loss 0.018 b_loss 0.000
epoch num: 6
fps step: 1476 fps step and policy inference: 1419 fps total: 1409 epoch: 6/100000
epoch: 6 mean_rewards: [287.72] mean_lengths: 300.00003
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.908 c_loss 0.020 b_loss 0.000
a_loss 0.900 c_loss 0.018 b_loss 0.000
a_loss 0.890 c_loss 0.015 b_loss 0.000
a_loss 0.879 c_loss 0.013 b_loss 0.000
a_loss 0.865 c_loss 0.011 b_loss 0.000
a_loss 0.853 c_loss 0.010 b_loss 0.000
epoch num: 7
fps step: 1480 fps step and policy inference: 1422 fps total: 1411 epoch: 7/100000
epoch: 7 mean_rewards: [287.72] mean_lengths: 300.00003
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.013 b_loss 0.000
a_loss 0.898 c_loss 0.012 b_loss 0.000
a_loss 0.888 c_loss 0.010 b_loss 0.000
a_loss 0.878 c_loss 0.009 b_loss 0.000
a_loss 0.865 c_loss 0.008 b_loss 0.000
a_loss 0.853 c_loss 0.008 b_loss 0.000
epoch num: 8
fps step: 1493 fps step and policy inference: 1434 fps total: 1423 epoch: 8/100000
epoch: 8 mean_rewards: [287.72] mean_lengths: 300.00003
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.010 b_loss 0.000
a_loss 0.897 c_loss 0.009 b_loss 0.000
a_loss 0.888 c_loss 0.009 b_loss 0.000
a_loss 0.878 c_loss 0.008 b_loss 0.000
a_loss 0.866 c_loss 0.007 b_loss 0.000
a_loss 0.854 c_loss 0.007 b_loss 0.000
epoch num: 9
fps step: 1496 fps step and policy inference: 1437 fps total: 1426 epoch: 9/100000
epoch: 9 mean_rewards: [287.63] mean_lengths: 300.00003
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.855 c_loss 0.011 b_loss 0.000
a_loss 0.849 c_loss 0.011 b_loss 0.000
a_loss 0.840 c_loss 0.010 b_loss 0.000
a_loss 0.830 c_loss 0.010 b_loss 0.000
a_loss 0.819 c_loss 0.009 b_loss 0.000
a_loss 0.808 c_loss 0.009 b_loss 0.000
epoch num: 10
fps step: 1520 fps step and policy inference: 1457 fps total: 1445 epoch: 10/100000
epoch: 10 mean_rewards: [289.59] mean_lengths: 300.00003
saving next best rewards:  [289.59]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.899 c_loss 0.009 b_loss 0.000
a_loss 0.892 c_loss 0.008 b_loss 0.000
a_loss 0.882 c_loss 0.008 b_loss 0.000
a_loss 0.872 c_loss 0.008 b_loss 0.000
a_loss 0.860 c_loss 0.007 b_loss 0.000
a_loss 0.847 c_loss 0.007 b_loss 0.000
epoch num: 11
fps step: 1498 fps step and policy inference: 1440 fps total: 1429 epoch: 11/100000
epoch: 11 mean_rewards: [289.59] mean_lengths: 300.00003
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.899 c_loss 0.008 b_loss 0.000
a_loss 0.893 c_loss 0.008 b_loss 0.000
a_loss 0.884 c_loss 0.008 b_loss 0.000
a_loss 0.875 c_loss 0.007 b_loss 0.000
a_loss 0.863 c_loss 0.007 b_loss 0.000
a_loss 0.849 c_loss 0.007 b_loss 0.000
epoch num: 12
fps step: 1456 fps step and policy inference: 1401 fps total: 1391 epoch: 12/100000
epoch: 12 mean_rewards: [289.59] mean_lengths: 300.00003
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.897 c_loss 0.009 b_loss 0.000
a_loss 0.890 c_loss 0.008 b_loss 0.000
a_loss 0.881 c_loss 0.008 b_loss 0.000
a_loss 0.871 c_loss 0.008 b_loss 0.000
a_loss 0.859 c_loss 0.008 b_loss 0.000
a_loss 0.845 c_loss 0.007 b_loss 0.000
epoch num: 13
fps step: 1444 fps step and policy inference: 1387 fps total: 1377 epoch: 13/100000
epoch: 13 mean_rewards: [289.8] mean_lengths: 300.00003
saving next best rewards:  [289.8]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.897 c_loss 0.008 b_loss 0.000
a_loss 0.891 c_loss 0.007 b_loss 0.000
a_loss 0.882 c_loss 0.007 b_loss 0.000
a_loss 0.873 c_loss 0.007 b_loss 0.000
a_loss 0.860 c_loss 0.007 b_loss 0.000
a_loss 0.847 c_loss 0.007 b_loss 0.000
epoch num: 14
fps step: 1439 fps step and policy inference: 1384 fps total: 1374 epoch: 14/100000
epoch: 14 mean_rewards: [289.8] mean_lengths: 300.00003
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.861 c_loss 0.007 b_loss 0.000
a_loss 0.856 c_loss 0.007 b_loss 0.000
a_loss 0.848 c_loss 0.007 b_loss 0.000
a_loss 0.839 c_loss 0.007 b_loss 0.000
a_loss 0.828 c_loss 0.006 b_loss 0.000
a_loss 0.815 c_loss 0.006 b_loss 0.000
epoch num: 15
fps step: 1470 fps step and policy inference: 1412 fps total: 1401 epoch: 15/100000
epoch: 15 mean_rewards: [287.51] mean_lengths: 300.00003
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.901 c_loss 0.008 b_loss 0.000
a_loss 0.894 c_loss 0.007 b_loss 0.000
a_loss 0.885 c_loss 0.007 b_loss 0.000
a_loss 0.875 c_loss 0.007 b_loss 0.000
a_loss 0.862 c_loss 0.007 b_loss 0.000
a_loss 0.849 c_loss 0.007 b_loss 0.000
epoch num: 16
fps step: 1464 fps step and policy inference: 1408 fps total: 1397 epoch: 16/100000
epoch: 16 mean_rewards: [287.51] mean_lengths: 300.00003
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.898 c_loss 0.006 b_loss 0.000
a_loss 0.891 c_loss 0.006 b_loss 0.000
a_loss 0.882 c_loss 0.006 b_loss 0.000
a_loss 0.873 c_loss 0.006 b_loss 0.000
a_loss 0.860 c_loss 0.006 b_loss 0.000
a_loss 0.847 c_loss 0.006 b_loss 0.000
epoch num: 17
fps step: 1453 fps step and policy inference: 1398 fps total: 1387 epoch: 17/100000
epoch: 17 mean_rewards: [287.51] mean_lengths: 300.00003
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.895 c_loss 0.006 b_loss 0.000
a_loss 0.889 c_loss 0.006 b_loss 0.000
a_loss 0.880 c_loss 0.006 b_loss 0.000
a_loss 0.870 c_loss 0.006 b_loss 0.000
a_loss 0.857 c_loss 0.006 b_loss 0.000
a_loss 0.844 c_loss 0.006 b_loss 0.000
epoch num: 18
fps step: 1516 fps step and policy inference: 1455 fps total: 1443 epoch: 18/100000
epoch: 18 mean_rewards: [287.54] mean_lengths: 300.00003
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.843 c_loss 0.007 b_loss 0.000
a_loss 0.837 c_loss 0.007 b_loss 0.000
a_loss 0.829 c_loss 0.007 b_loss 0.000
a_loss 0.820 c_loss 0.007 b_loss 0.000
a_loss 0.808 c_loss 0.007 b_loss 0.000
a_loss 0.796 c_loss 0.007 b_loss 0.000
epoch num: 19
fps step: 1510 fps step and policy inference: 1447 fps total: 1436 epoch: 19/100000
epoch: 19 mean_rewards: [288.61] mean_lengths: 300.00003
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.896 c_loss 0.006 b_loss 0.000
a_loss 0.889 c_loss 0.006 b_loss 0.000
a_loss 0.881 c_loss 0.006 b_loss 0.000
a_loss 0.871 c_loss 0.006 b_loss 0.000
a_loss 0.859 c_loss 0.005 b_loss 0.000
a_loss 0.846 c_loss 0.005 b_loss 0.000
epoch num: 20
fps step: 1475 fps step and policy inference: 1418 fps total: 1407 epoch: 20/100000
epoch: 20 mean_rewards: [288.61] mean_lengths: 300.00003
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.899 c_loss 0.006 b_loss 0.000
a_loss 0.893 c_loss 0.005 b_loss 0.000
a_loss 0.884 c_loss 0.005 b_loss 0.000
a_loss 0.875 c_loss 0.005 b_loss 0.000
a_loss 0.862 c_loss 0.005 b_loss 0.000
a_loss 0.849 c_loss 0.005 b_loss 0.000
epoch num: 21
fps step: 1451 fps step and policy inference: 1396 fps total: 1385 epoch: 21/100000
epoch: 21 mean_rewards: [288.61] mean_lengths: 300.00003
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.896 c_loss 0.006 b_loss 0.000
a_loss 0.889 c_loss 0.006 b_loss 0.000
a_loss 0.880 c_loss 0.006 b_loss 0.000
a_loss 0.871 c_loss 0.006 b_loss 0.000
a_loss 0.857 c_loss 0.006 b_loss 0.000
a_loss 0.843 c_loss 0.005 b_loss 0.000
epoch num: 22
fps step: 1454 fps step and policy inference: 1398 fps total: 1387 epoch: 22/100000
epoch: 22 mean_rewards: [287.46] mean_lengths: 298.66003
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.891 c_loss 0.005 b_loss 0.000
a_loss 0.885 c_loss 0.005 b_loss 0.000
a_loss 0.877 c_loss 0.005 b_loss 0.000
a_loss 0.868 c_loss 0.005 b_loss 0.000
a_loss 0.855 c_loss 0.005 b_loss 0.000
a_loss 0.842 c_loss 0.005 b_loss 0.000
epoch num: 23
fps step: 1436 fps step and policy inference: 1380 fps total: 1370 epoch: 23/100000
epoch: 23 mean_rewards: [287.42] mean_lengths: 298.67343
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.848 c_loss 0.006 b_loss 0.000
a_loss 0.843 c_loss 0.006 b_loss 0.000
a_loss 0.835 c_loss 0.006 b_loss 0.000
a_loss 0.826 c_loss 0.006 b_loss 0.000
a_loss 0.815 c_loss 0.006 b_loss 0.000
a_loss 0.803 c_loss 0.006 b_loss 0.000
epoch num: 24
fps step: 1461 fps step and policy inference: 1403 fps total: 1392 epoch: 24/100000
epoch: 24 mean_rewards: [296.43] mean_lengths: 300.0
saving next best rewards:  [296.43]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.897 c_loss 0.006 b_loss 0.000
a_loss 0.890 c_loss 0.006 b_loss 0.000
a_loss 0.881 c_loss 0.006 b_loss 0.000
a_loss 0.872 c_loss 0.005 b_loss 0.000
a_loss 0.859 c_loss 0.005 b_loss 0.000
a_loss 0.845 c_loss 0.005 b_loss 0.000
epoch num: 25
fps step: 1469 fps step and policy inference: 1412 fps total: 1401 epoch: 25/100000
epoch: 25 mean_rewards: [296.43] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.892 c_loss 0.005 b_loss 0.000
a_loss 0.886 c_loss 0.005 b_loss 0.000
a_loss 0.877 c_loss 0.005 b_loss 0.000
a_loss 0.868 c_loss 0.005 b_loss 0.000
a_loss 0.855 c_loss 0.005 b_loss 0.000
a_loss 0.842 c_loss 0.005 b_loss 0.000
epoch num: 26
fps step: 1468 fps step and policy inference: 1412 fps total: 1401 epoch: 26/100000
epoch: 26 mean_rewards: [296.43] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.893 c_loss 0.005 b_loss 0.000
a_loss 0.886 c_loss 0.005 b_loss 0.000
a_loss 0.877 c_loss 0.005 b_loss 0.000
a_loss 0.868 c_loss 0.005 b_loss 0.000
a_loss 0.856 c_loss 0.005 b_loss 0.000
a_loss 0.844 c_loss 0.005 b_loss 0.000
epoch num: 27
fps step: 1485 fps step and policy inference: 1424 fps total: 1414 epoch: 27/100000
epoch: 27 mean_rewards: [295.91] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.894 c_loss 0.005 b_loss 0.000
a_loss 0.887 c_loss 0.005 b_loss 0.000
a_loss 0.879 c_loss 0.005 b_loss 0.000
a_loss 0.871 c_loss 0.005 b_loss 0.000
a_loss 0.858 c_loss 0.005 b_loss 0.000
a_loss 0.844 c_loss 0.005 b_loss 0.000
epoch num: 28
fps step: 1505 fps step and policy inference: 1445 fps total: 1434 epoch: 28/100000
epoch: 28 mean_rewards: [295.91] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.837 c_loss 0.005 b_loss 0.000
a_loss 0.831 c_loss 0.005 b_loss 0.000
a_loss 0.824 c_loss 0.005 b_loss 0.000
a_loss 0.815 c_loss 0.005 b_loss 0.000
a_loss 0.803 c_loss 0.005 b_loss 0.000
a_loss 0.791 c_loss 0.005 b_loss 0.000
epoch num: 29
fps step: 1485 fps step and policy inference: 1425 fps total: 1413 epoch: 29/100000
epoch: 29 mean_rewards: [291.65] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.887 c_loss 0.005 b_loss 0.000
a_loss 0.881 c_loss 0.005 b_loss 0.000
a_loss 0.872 c_loss 0.005 b_loss 0.000
a_loss 0.863 c_loss 0.005 b_loss 0.000
a_loss 0.851 c_loss 0.005 b_loss 0.000
a_loss 0.838 c_loss 0.005 b_loss 0.000
epoch num: 30
fps step: 1473 fps step and policy inference: 1416 fps total: 1405 epoch: 30/100000
epoch: 30 mean_rewards: [291.65] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.890 c_loss 0.005 b_loss 0.000
a_loss 0.884 c_loss 0.005 b_loss 0.000
a_loss 0.875 c_loss 0.005 b_loss 0.000
a_loss 0.865 c_loss 0.005 b_loss 0.000
a_loss 0.852 c_loss 0.005 b_loss 0.000
a_loss 0.840 c_loss 0.005 b_loss 0.000
epoch num: 31
fps step: 1443 fps step and policy inference: 1387 fps total: 1376 epoch: 31/100000
epoch: 31 mean_rewards: [291.86] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.886 c_loss 0.005 b_loss 0.000
a_loss 0.880 c_loss 0.004 b_loss 0.000
a_loss 0.871 c_loss 0.004 b_loss 0.000
a_loss 0.862 c_loss 0.004 b_loss 0.000
a_loss 0.849 c_loss 0.004 b_loss 0.000
a_loss 0.836 c_loss 0.004 b_loss 0.000
epoch num: 32
fps step: 1445 fps step and policy inference: 1390 fps total: 1380 epoch: 32/100000
epoch: 32 mean_rewards: [291.7] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.831 c_loss 0.005 b_loss 0.000
a_loss 0.825 c_loss 0.005 b_loss 0.000
a_loss 0.818 c_loss 0.005 b_loss 0.000
a_loss 0.810 c_loss 0.005 b_loss 0.000
a_loss 0.800 c_loss 0.005 b_loss 0.000
a_loss 0.788 c_loss 0.005 b_loss 0.000
epoch num: 33
fps step: 1458 fps step and policy inference: 1398 fps total: 1387 epoch: 33/100000
epoch: 33 mean_rewards: [289.19] mean_lengths: 297.02
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.894 c_loss 0.005 b_loss 0.000
a_loss 0.888 c_loss 0.005 b_loss 0.000
a_loss 0.879 c_loss 0.005 b_loss 0.000
a_loss 0.869 c_loss 0.005 b_loss 0.000
a_loss 0.857 c_loss 0.005 b_loss 0.000
a_loss 0.843 c_loss 0.005 b_loss 0.000
epoch num: 34
fps step: 1479 fps step and policy inference: 1422 fps total: 1411 epoch: 34/100000
epoch: 34 mean_rewards: [289.19] mean_lengths: 297.02
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.891 c_loss 0.004 b_loss 0.000
a_loss 0.885 c_loss 0.004 b_loss 0.000
a_loss 0.876 c_loss 0.004 b_loss 0.000
a_loss 0.867 c_loss 0.004 b_loss 0.000
a_loss 0.855 c_loss 0.004 b_loss 0.000
a_loss 0.842 c_loss 0.004 b_loss 0.000
epoch num: 35
fps step: 1489 fps step and policy inference: 1431 fps total: 1420 epoch: 35/100000
epoch: 35 mean_rewards: [289.19] mean_lengths: 297.02
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.889 c_loss 0.004 b_loss 0.000
a_loss 0.883 c_loss 0.004 b_loss 0.000
a_loss 0.874 c_loss 0.004 b_loss 0.000
a_loss 0.865 c_loss 0.004 b_loss 0.000
a_loss 0.854 c_loss 0.004 b_loss 0.000
a_loss 0.841 c_loss 0.004 b_loss 0.000
epoch num: 36
fps step: 1488 fps step and policy inference: 1429 fps total: 1417 epoch: 36/100000
epoch: 36 mean_rewards: [289.47] mean_lengths: 297.04977
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.886 c_loss 0.005 b_loss 0.000
a_loss 0.880 c_loss 0.004 b_loss 0.000
a_loss 0.871 c_loss 0.004 b_loss 0.000
a_loss 0.861 c_loss 0.004 b_loss 0.000
a_loss 0.849 c_loss 0.004 b_loss 0.000
a_loss 0.836 c_loss 0.004 b_loss 0.000
epoch num: 37
fps step: 1489 fps step and policy inference: 1430 fps total: 1419 epoch: 37/100000
epoch: 37 mean_rewards: [290.11] mean_lengths: 297.07928
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.844 c_loss 0.005 b_loss 0.000
a_loss 0.839 c_loss 0.005 b_loss 0.000
a_loss 0.830 c_loss 0.005 b_loss 0.000
a_loss 0.822 c_loss 0.005 b_loss 0.000
a_loss 0.811 c_loss 0.005 b_loss 0.000
a_loss 0.799 c_loss 0.005 b_loss 0.000
epoch num: 38
fps step: 1512 fps step and policy inference: 1446 fps total: 1435 epoch: 38/100000
epoch: 38 mean_rewards: [289.64] mean_lengths: 294.1594
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.889 c_loss 0.004 b_loss 0.000
a_loss 0.883 c_loss 0.004 b_loss 0.000
a_loss 0.874 c_loss 0.004 b_loss 0.000
a_loss 0.865 c_loss 0.004 b_loss 0.000
a_loss 0.853 c_loss 0.004 b_loss 0.000
a_loss 0.840 c_loss 0.004 b_loss 0.000
epoch num: 39
fps step: 1484 fps step and policy inference: 1426 fps total: 1415 epoch: 39/100000
epoch: 39 mean_rewards: [289.64] mean_lengths: 294.1594
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.890 c_loss 0.004 b_loss 0.000
a_loss 0.884 c_loss 0.004 b_loss 0.000
a_loss 0.875 c_loss 0.004 b_loss 0.000
a_loss 0.866 c_loss 0.004 b_loss 0.000
a_loss 0.853 c_loss 0.004 b_loss 0.000
a_loss 0.840 c_loss 0.004 b_loss 0.000
epoch num: 40
fps step: 1455 fps step and policy inference: 1399 fps total: 1388 epoch: 40/100000
epoch: 40 mean_rewards: [289.64] mean_lengths: 294.1594
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.886 c_loss 0.004 b_loss 0.000
a_loss 0.880 c_loss 0.004 b_loss 0.000
a_loss 0.872 c_loss 0.004 b_loss 0.000
a_loss 0.862 c_loss 0.004 b_loss 0.000
a_loss 0.849 c_loss 0.004 b_loss 0.000
a_loss 0.836 c_loss 0.004 b_loss 0.000
epoch num: 41
fps step: 1432 fps step and policy inference: 1378 fps total: 1367 epoch: 41/100000
epoch: 41 mean_rewards: [289.56] mean_lengths: 294.21777
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.890 c_loss 0.004 b_loss 0.000
a_loss 0.885 c_loss 0.004 b_loss 0.000
a_loss 0.876 c_loss 0.004 b_loss 0.000
a_loss 0.867 c_loss 0.004 b_loss 0.000
a_loss 0.855 c_loss 0.004 b_loss 0.000
a_loss 0.842 c_loss 0.004 b_loss 0.000
epoch num: 42
fps step: 1431 fps step and policy inference: 1376 fps total: 1366 epoch: 42/100000
epoch: 42 mean_rewards: [289.15] mean_lengths: 294.27557
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.831 c_loss 0.005 b_loss 0.000
a_loss 0.825 c_loss 0.005 b_loss 0.000
a_loss 0.816 c_loss 0.005 b_loss 0.000
a_loss 0.808 c_loss 0.005 b_loss 0.000
a_loss 0.796 c_loss 0.005 b_loss 0.000
a_loss 0.784 c_loss 0.005 b_loss 0.000
epoch num: 43
fps step: 1498 fps step and policy inference: 1431 fps total: 1420 epoch: 43/100000
epoch: 43 mean_rewards: [290.43] mean_lengths: 297.08908
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.889 c_loss 0.004 b_loss 0.000
a_loss 0.883 c_loss 0.004 b_loss 0.000
a_loss 0.874 c_loss 0.004 b_loss 0.000
a_loss 0.865 c_loss 0.004 b_loss 0.000
a_loss 0.854 c_loss 0.004 b_loss 0.000
a_loss 0.841 c_loss 0.004 b_loss 0.000
epoch num: 44
fps step: 1486 fps step and policy inference: 1428 fps total: 1417 epoch: 44/100000
epoch: 44 mean_rewards: [290.43] mean_lengths: 297.08908
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.889 c_loss 0.004 b_loss 0.000
a_loss 0.883 c_loss 0.004 b_loss 0.000
a_loss 0.874 c_loss 0.004 b_loss 0.000
a_loss 0.865 c_loss 0.004 b_loss 0.000
a_loss 0.853 c_loss 0.004 b_loss 0.000
a_loss 0.839 c_loss 0.004 b_loss 0.000
epoch num: 45
fps step: 1469 fps step and policy inference: 1411 fps total: 1401 epoch: 45/100000
epoch: 45 mean_rewards: [290.35] mean_lengths: 297.11816
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.891 c_loss 0.004 b_loss 0.000
a_loss 0.885 c_loss 0.004 b_loss 0.000
a_loss 0.876 c_loss 0.004 b_loss 0.000
a_loss 0.866 c_loss 0.004 b_loss 0.000
a_loss 0.853 c_loss 0.004 b_loss 0.000
a_loss 0.840 c_loss 0.004 b_loss 0.000
epoch num: 46
fps step: 1388 fps step and policy inference: 1336 fps total: 1327 epoch: 46/100000
epoch: 46 mean_rewards: [290.64] mean_lengths: 297.14697
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.835 c_loss 0.004 b_loss 0.000
a_loss 0.830 c_loss 0.004 b_loss 0.000
a_loss 0.822 c_loss 0.004 b_loss 0.000
a_loss 0.814 c_loss 0.004 b_loss 0.000
a_loss 0.803 c_loss 0.004 b_loss 0.000
a_loss 0.791 c_loss 0.004 b_loss 0.000
epoch num: 47
fps step: 1438 fps step and policy inference: 1377 fps total: 1367 epoch: 47/100000
epoch: 47 mean_rewards: [297.71] mean_lengths: 300.0
saving next best rewards:  [297.71]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.890 c_loss 0.004 b_loss 0.000
a_loss 0.884 c_loss 0.004 b_loss 0.000
a_loss 0.875 c_loss 0.003 b_loss 0.000
a_loss 0.865 c_loss 0.003 b_loss 0.000
a_loss 0.852 c_loss 0.003 b_loss 0.000
a_loss 0.841 c_loss 0.003 b_loss 0.000
epoch num: 48
fps step: 1464 fps step and policy inference: 1406 fps total: 1395 epoch: 48/100000
epoch: 48 mean_rewards: [297.71] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.891 c_loss 0.004 b_loss 0.000
a_loss 0.885 c_loss 0.004 b_loss 0.000
a_loss 0.875 c_loss 0.004 b_loss 0.000
a_loss 0.865 c_loss 0.003 b_loss 0.000
a_loss 0.853 c_loss 0.003 b_loss 0.000
a_loss 0.840 c_loss 0.003 b_loss 0.000
epoch num: 49
fps step: 1461 fps step and policy inference: 1404 fps total: 1393 epoch: 49/100000
epoch: 49 mean_rewards: [297.71] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.888 c_loss 0.003 b_loss 0.000
a_loss 0.882 c_loss 0.003 b_loss 0.000
a_loss 0.873 c_loss 0.003 b_loss 0.000
a_loss 0.862 c_loss 0.003 b_loss 0.000
a_loss 0.850 c_loss 0.003 b_loss 0.000
a_loss 0.838 c_loss 0.003 b_loss 0.000
epoch num: 50
fps step: 1479 fps step and policy inference: 1421 fps total: 1410 epoch: 50/100000
epoch: 50 mean_rewards: [297.56] mean_lengths: 300.0
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/last_Humanoid_ep_50_rew_297.56354.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.890 c_loss 0.003 b_loss 0.000
a_loss 0.884 c_loss 0.003 b_loss 0.000
a_loss 0.875 c_loss 0.003 b_loss 0.000
a_loss 0.865 c_loss 0.003 b_loss 0.000
a_loss 0.854 c_loss 0.003 b_loss 0.000
a_loss 0.841 c_loss 0.003 b_loss 0.000
epoch num: 51
fps step: 1504 fps step and policy inference: 1443 fps total: 1432 epoch: 51/100000
epoch: 51 mean_rewards: [297.7] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.846 c_loss 0.004 b_loss 0.000
a_loss 0.840 c_loss 0.004 b_loss 0.000
a_loss 0.832 c_loss 0.004 b_loss 0.000
a_loss 0.823 c_loss 0.004 b_loss 0.000
a_loss 0.813 c_loss 0.004 b_loss 0.000
a_loss 0.800 c_loss 0.004 b_loss 0.000
epoch num: 52
fps step: 1490 fps step and policy inference: 1425 fps total: 1414 epoch: 52/100000
epoch: 52 mean_rewards: [293.92] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.891 c_loss 0.003 b_loss 0.000
a_loss 0.885 c_loss 0.003 b_loss 0.000
a_loss 0.875 c_loss 0.003 b_loss 0.000
a_loss 0.865 c_loss 0.003 b_loss 0.000
a_loss 0.853 c_loss 0.003 b_loss 0.000
a_loss 0.840 c_loss 0.003 b_loss 0.000
epoch num: 53
fps step: 1464 fps step and policy inference: 1407 fps total: 1396 epoch: 53/100000
epoch: 53 mean_rewards: [293.92] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.887 c_loss 0.003 b_loss 0.000
a_loss 0.881 c_loss 0.003 b_loss 0.000
a_loss 0.872 c_loss 0.003 b_loss 0.000
a_loss 0.863 c_loss 0.003 b_loss 0.000
a_loss 0.852 c_loss 0.003 b_loss 0.000
a_loss 0.840 c_loss 0.003 b_loss 0.000
epoch num: 54
fps step: 1428 fps step and policy inference: 1375 fps total: 1364 epoch: 54/100000
epoch: 54 mean_rewards: [293.92] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.895 c_loss 0.003 b_loss 0.000
a_loss 0.889 c_loss 0.003 b_loss 0.000
a_loss 0.880 c_loss 0.003 b_loss 0.000
a_loss 0.871 c_loss 0.003 b_loss 0.000
a_loss 0.858 c_loss 0.003 b_loss 0.000
a_loss 0.845 c_loss 0.003 b_loss 0.000
epoch num: 55
fps step: 1474 fps step and policy inference: 1416 fps total: 1405 epoch: 55/100000
epoch: 55 mean_rewards: [294.58] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.891 c_loss 0.003 b_loss 0.000
a_loss 0.886 c_loss 0.003 b_loss 0.000
a_loss 0.876 c_loss 0.003 b_loss 0.000
a_loss 0.866 c_loss 0.003 b_loss 0.000
a_loss 0.855 c_loss 0.003 b_loss 0.000
a_loss 0.842 c_loss 0.003 b_loss 0.000
epoch num: 56
fps step: 1504 fps step and policy inference: 1444 fps total: 1433 epoch: 56/100000
epoch: 56 mean_rewards: [294.6] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.832 c_loss 0.003 b_loss 0.000
a_loss 0.827 c_loss 0.003 b_loss 0.000
a_loss 0.818 c_loss 0.003 b_loss 0.000
a_loss 0.811 c_loss 0.003 b_loss 0.000
a_loss 0.801 c_loss 0.003 b_loss 0.000
a_loss 0.790 c_loss 0.003 b_loss 0.000
epoch num: 57
fps step: 1483 fps step and policy inference: 1418 fps total: 1406 epoch: 57/100000
epoch: 57 mean_rewards: [291.64] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.894 c_loss 0.003 b_loss 0.000
a_loss 0.887 c_loss 0.003 b_loss 0.000
a_loss 0.878 c_loss 0.003 b_loss 0.000
a_loss 0.868 c_loss 0.003 b_loss 0.000
a_loss 0.856 c_loss 0.003 b_loss 0.000
a_loss 0.843 c_loss 0.003 b_loss 0.000
epoch num: 58
fps step: 1467 fps step and policy inference: 1411 fps total: 1400 epoch: 58/100000
epoch: 58 mean_rewards: [291.64] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.890 c_loss 0.003 b_loss 0.000
a_loss 0.883 c_loss 0.003 b_loss 0.000
a_loss 0.874 c_loss 0.003 b_loss 0.000
a_loss 0.864 c_loss 0.003 b_loss 0.000
a_loss 0.852 c_loss 0.003 b_loss 0.000
a_loss 0.839 c_loss 0.003 b_loss 0.000
epoch num: 59
fps step: 1430 fps step and policy inference: 1376 fps total: 1366 epoch: 59/100000
epoch: 59 mean_rewards: [291.72] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.891 c_loss 0.003 b_loss 0.000
a_loss 0.885 c_loss 0.003 b_loss 0.000
a_loss 0.876 c_loss 0.003 b_loss 0.000
a_loss 0.867 c_loss 0.003 b_loss 0.000
a_loss 0.855 c_loss 0.003 b_loss 0.000
a_loss 0.841 c_loss 0.003 b_loss 0.000
epoch num: 60
fps step: 1443 fps step and policy inference: 1387 fps total: 1376 epoch: 60/100000
epoch: 60 mean_rewards: [291.93] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.856 c_loss 0.003 b_loss 0.000
a_loss 0.850 c_loss 0.003 b_loss 0.000
a_loss 0.842 c_loss 0.003 b_loss 0.000
a_loss 0.833 c_loss 0.003 b_loss 0.000
a_loss 0.820 c_loss 0.003 b_loss 0.000
a_loss 0.807 c_loss 0.003 b_loss 0.000
epoch num: 61
fps step: 1453 fps step and policy inference: 1393 fps total: 1383 epoch: 61/100000
epoch: 61 mean_rewards: [297.11] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.892 c_loss 0.003 b_loss 0.000
a_loss 0.886 c_loss 0.003 b_loss 0.000
a_loss 0.877 c_loss 0.003 b_loss 0.000
a_loss 0.868 c_loss 0.003 b_loss 0.000
a_loss 0.856 c_loss 0.003 b_loss 0.000
a_loss 0.842 c_loss 0.003 b_loss 0.000
epoch num: 62
fps step: 1467 fps step and policy inference: 1408 fps total: 1397 epoch: 62/100000
epoch: 62 mean_rewards: [297.03] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.892 c_loss 0.003 b_loss 0.000
a_loss 0.885 c_loss 0.003 b_loss 0.000
a_loss 0.877 c_loss 0.003 b_loss 0.000
a_loss 0.868 c_loss 0.003 b_loss 0.000
a_loss 0.856 c_loss 0.003 b_loss 0.000
a_loss 0.843 c_loss 0.003 b_loss 0.000
epoch num: 63
fps step: 1459 fps step and policy inference: 1403 fps total: 1392 epoch: 63/100000
epoch: 63 mean_rewards: [297.03] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.895 c_loss 0.003 b_loss 0.000
a_loss 0.889 c_loss 0.003 b_loss 0.000
a_loss 0.880 c_loss 0.003 b_loss 0.000
a_loss 0.870 c_loss 0.003 b_loss 0.000
a_loss 0.857 c_loss 0.003 b_loss 0.000
a_loss 0.844 c_loss 0.003 b_loss 0.000
epoch num: 64
fps step: 1473 fps step and policy inference: 1416 fps total: 1405 epoch: 64/100000
epoch: 64 mean_rewards: [296.74] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.893 c_loss 0.002 b_loss 0.000
a_loss 0.886 c_loss 0.002 b_loss 0.000
a_loss 0.877 c_loss 0.002 b_loss 0.000
a_loss 0.867 c_loss 0.002 b_loss 0.000
a_loss 0.855 c_loss 0.002 b_loss 0.000
a_loss 0.842 c_loss 0.002 b_loss 0.000
epoch num: 65
fps step: 1450 fps step and policy inference: 1394 fps total: 1383 epoch: 65/100000
epoch: 65 mean_rewards: [296.47] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.846 c_loss 0.003 b_loss 0.000
a_loss 0.840 c_loss 0.003 b_loss 0.000
a_loss 0.832 c_loss 0.003 b_loss 0.000
a_loss 0.823 c_loss 0.003 b_loss 0.000
a_loss 0.813 c_loss 0.003 b_loss 0.000
a_loss 0.801 c_loss 0.003 b_loss 0.000
epoch num: 66
fps step: 1485 fps step and policy inference: 1420 fps total: 1409 epoch: 66/100000
epoch: 66 mean_rewards: [290.88] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.894 c_loss 0.003 b_loss 0.000
a_loss 0.887 c_loss 0.003 b_loss 0.000
a_loss 0.878 c_loss 0.003 b_loss 0.000
a_loss 0.868 c_loss 0.003 b_loss 0.000
a_loss 0.856 c_loss 0.003 b_loss 0.000
a_loss 0.843 c_loss 0.003 b_loss 0.000
epoch num: 67
fps step: 1443 fps step and policy inference: 1388 fps total: 1377 epoch: 67/100000
epoch: 67 mean_rewards: [290.88] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.895 c_loss 0.002 b_loss 0.000
a_loss 0.888 c_loss 0.002 b_loss 0.000
a_loss 0.878 c_loss 0.002 b_loss 0.000
a_loss 0.868 c_loss 0.002 b_loss 0.000
a_loss 0.856 c_loss 0.002 b_loss 0.000
a_loss 0.844 c_loss 0.002 b_loss 0.000
epoch num: 68
fps step: 1457 fps step and policy inference: 1401 fps total: 1390 epoch: 68/100000
epoch: 68 mean_rewards: [290.88] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.897 c_loss 0.002 b_loss 0.000
a_loss 0.890 c_loss 0.002 b_loss 0.000
a_loss 0.881 c_loss 0.002 b_loss 0.000
a_loss 0.872 c_loss 0.002 b_loss 0.000
a_loss 0.860 c_loss 0.002 b_loss 0.000
a_loss 0.847 c_loss 0.002 b_loss 0.000
epoch num: 69
fps step: 1496 fps step and policy inference: 1436 fps total: 1425 epoch: 69/100000
epoch: 69 mean_rewards: [291.06] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.897 c_loss 0.003 b_loss 0.000
a_loss 0.890 c_loss 0.003 b_loss 0.000
a_loss 0.881 c_loss 0.003 b_loss 0.000
a_loss 0.872 c_loss 0.002 b_loss 0.000
a_loss 0.859 c_loss 0.002 b_loss 0.000
a_loss 0.845 c_loss 0.002 b_loss 0.000
epoch num: 70
fps step: 1505 fps step and policy inference: 1445 fps total: 1433 epoch: 70/100000
epoch: 70 mean_rewards: [291.16] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.837 c_loss 0.003 b_loss 0.000
a_loss 0.831 c_loss 0.003 b_loss 0.000
a_loss 0.824 c_loss 0.003 b_loss 0.000
a_loss 0.816 c_loss 0.003 b_loss 0.000
a_loss 0.804 c_loss 0.003 b_loss 0.000
a_loss 0.792 c_loss 0.003 b_loss 0.000
epoch num: 71
fps step: 1505 fps step and policy inference: 1439 fps total: 1428 epoch: 71/100000
epoch: 71 mean_rewards: [294.67] mean_lengths: 297.08908
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.894 c_loss 0.002 b_loss 0.000
a_loss 0.887 c_loss 0.002 b_loss 0.000
a_loss 0.879 c_loss 0.002 b_loss 0.000
a_loss 0.870 c_loss 0.002 b_loss 0.000
a_loss 0.857 c_loss 0.002 b_loss 0.000
a_loss 0.844 c_loss 0.002 b_loss 0.000
epoch num: 72
fps step: 1477 fps step and policy inference: 1420 fps total: 1409 epoch: 72/100000
epoch: 72 mean_rewards: [294.67] mean_lengths: 297.08908
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.895 c_loss 0.002 b_loss 0.000
a_loss 0.888 c_loss 0.002 b_loss 0.000
a_loss 0.880 c_loss 0.002 b_loss 0.000
a_loss 0.870 c_loss 0.002 b_loss 0.000
a_loss 0.857 c_loss 0.002 b_loss 0.000
a_loss 0.844 c_loss 0.002 b_loss 0.000
epoch num: 73
fps step: 1494 fps step and policy inference: 1434 fps total: 1423 epoch: 73/100000
epoch: 73 mean_rewards: [295.74] mean_lengths: 297.11816
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.895 c_loss 0.002 b_loss 0.000
a_loss 0.889 c_loss 0.002 b_loss 0.000
a_loss 0.880 c_loss 0.002 b_loss 0.000
a_loss 0.871 c_loss 0.002 b_loss 0.000
a_loss 0.858 c_loss 0.002 b_loss 0.000
a_loss 0.845 c_loss 0.002 b_loss 0.000
epoch num: 74
fps step: 1481 fps step and policy inference: 1423 fps total: 1412 epoch: 74/100000
epoch: 74 mean_rewards: [295.88] mean_lengths: 297.14697
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.894 c_loss 0.002 b_loss 0.000
a_loss 0.887 c_loss 0.002 b_loss 0.000
a_loss 0.879 c_loss 0.002 b_loss 0.000
a_loss 0.871 c_loss 0.002 b_loss 0.000
a_loss 0.858 c_loss 0.002 b_loss 0.000
a_loss 0.844 c_loss 0.002 b_loss 0.000
epoch num: 75
fps step: 1461 fps step and policy inference: 1404 fps total: 1393 epoch: 75/100000
epoch: 75 mean_rewards: [295.98] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.884 c_loss 0.003 b_loss 0.000
a_loss 0.877 c_loss 0.003 b_loss 0.000
a_loss 0.869 c_loss 0.003 b_loss 0.000
a_loss 0.860 c_loss 0.003 b_loss 0.000
a_loss 0.847 c_loss 0.003 b_loss 0.000
a_loss 0.834 c_loss 0.002 b_loss 0.000
epoch num: 76
fps step: 1490 fps step and policy inference: 1425 fps total: 1414 epoch: 76/100000
epoch: 76 mean_rewards: [16.59] mean_lengths: 15.682986
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.895 c_loss 0.002 b_loss 0.000
a_loss 0.889 c_loss 0.002 b_loss 0.000
a_loss 0.880 c_loss 0.002 b_loss 0.000
a_loss 0.871 c_loss 0.002 b_loss 0.000
a_loss 0.858 c_loss 0.002 b_loss 0.000
a_loss 0.845 c_loss 0.002 b_loss 0.000
epoch num: 77
fps step: 1420 fps step and policy inference: 1367 fps total: 1357 epoch: 77/100000
epoch: 77 mean_rewards: [16.59] mean_lengths: 15.682986
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.897 c_loss 0.002 b_loss 0.000
a_loss 0.892 c_loss 0.002 b_loss 0.000
a_loss 0.883 c_loss 0.002 b_loss 0.000
a_loss 0.874 c_loss 0.002 b_loss 0.000
a_loss 0.862 c_loss 0.002 b_loss 0.000
a_loss 0.849 c_loss 0.002 b_loss 0.000
epoch num: 78
fps step: 1443 fps step and policy inference: 1388 fps total: 1377 epoch: 78/100000
epoch: 78 mean_rewards: [19.39] mean_lengths: 18.526155
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.899 c_loss 0.002 b_loss 0.000
a_loss 0.892 c_loss 0.002 b_loss 0.000
a_loss 0.883 c_loss 0.002 b_loss 0.000
a_loss 0.874 c_loss 0.002 b_loss 0.000
a_loss 0.862 c_loss 0.002 b_loss 0.000
a_loss 0.849 c_loss 0.002 b_loss 0.000
epoch num: 79
fps step: 1446 fps step and policy inference: 1391 fps total: 1380 epoch: 79/100000
epoch: 79 mean_rewards: [22.64] mean_lengths: 21.340893
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.842 c_loss 0.002 b_loss 0.000
a_loss 0.836 c_loss 0.002 b_loss 0.000
a_loss 0.829 c_loss 0.002 b_loss 0.000
a_loss 0.821 c_loss 0.002 b_loss 0.000
a_loss 0.810 c_loss 0.002 b_loss 0.000
a_loss 0.798 c_loss 0.002 b_loss 0.000
epoch num: 80
fps step: 1480 fps step and policy inference: 1416 fps total: 1405 epoch: 80/100000
epoch: 80 mean_rewards: [291.94] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.899 c_loss 0.002 b_loss 0.000
a_loss 0.893 c_loss 0.002 b_loss 0.000
a_loss 0.884 c_loss 0.002 b_loss 0.000
a_loss 0.875 c_loss 0.002 b_loss 0.000
a_loss 0.862 c_loss 0.002 b_loss 0.000
a_loss 0.850 c_loss 0.002 b_loss 0.000
epoch num: 81
fps step: 1488 fps step and policy inference: 1430 fps total: 1419 epoch: 81/100000
epoch: 81 mean_rewards: [291.94] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.900 c_loss 0.002 b_loss 0.000
a_loss 0.893 c_loss 0.002 b_loss 0.000
a_loss 0.884 c_loss 0.002 b_loss 0.000
a_loss 0.875 c_loss 0.002 b_loss 0.000
a_loss 0.862 c_loss 0.002 b_loss 0.000
a_loss 0.849 c_loss 0.002 b_loss 0.000
epoch num: 82
fps step: 1433 fps step and policy inference: 1378 fps total: 1368 epoch: 82/100000
epoch: 82 mean_rewards: [291.94] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.900 c_loss 0.002 b_loss 0.000
a_loss 0.894 c_loss 0.002 b_loss 0.000
a_loss 0.885 c_loss 0.002 b_loss 0.000
a_loss 0.875 c_loss 0.002 b_loss 0.000
a_loss 0.862 c_loss 0.002 b_loss 0.000
a_loss 0.849 c_loss 0.002 b_loss 0.000
epoch num: 83
fps step: 1456 fps step and policy inference: 1400 fps total: 1389 epoch: 83/100000
epoch: 83 mean_rewards: [292.12] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.899 c_loss 0.002 b_loss 0.000
a_loss 0.893 c_loss 0.002 b_loss 0.000
a_loss 0.884 c_loss 0.002 b_loss 0.000
a_loss 0.874 c_loss 0.002 b_loss 0.000
a_loss 0.861 c_loss 0.002 b_loss 0.000
a_loss 0.848 c_loss 0.002 b_loss 0.000
epoch num: 84
fps step: 1481 fps step and policy inference: 1423 fps total: 1411 epoch: 84/100000
epoch: 84 mean_rewards: [291.96] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.850 c_loss 0.002 b_loss 0.000
a_loss 0.845 c_loss 0.002 b_loss 0.000
a_loss 0.836 c_loss 0.002 b_loss 0.000
a_loss 0.827 c_loss 0.002 b_loss 0.000
a_loss 0.816 c_loss 0.002 b_loss 0.000
a_loss 0.804 c_loss 0.002 b_loss 0.000
epoch num: 85
fps step: 1482 fps step and policy inference: 1417 fps total: 1406 epoch: 85/100000
epoch: 85 mean_rewards: [295.25] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.896 c_loss 0.002 b_loss 0.000
a_loss 0.889 c_loss 0.002 b_loss 0.000
a_loss 0.881 c_loss 0.002 b_loss 0.000
a_loss 0.872 c_loss 0.002 b_loss 0.000
a_loss 0.860 c_loss 0.002 b_loss 0.000
a_loss 0.845 c_loss 0.002 b_loss 0.000
epoch num: 86
fps step: 1471 fps step and policy inference: 1414 fps total: 1403 epoch: 86/100000
epoch: 86 mean_rewards: [295.25] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.899 c_loss 0.002 b_loss 0.000
a_loss 0.893 c_loss 0.002 b_loss 0.000
a_loss 0.884 c_loss 0.002 b_loss 0.000
a_loss 0.874 c_loss 0.002 b_loss 0.000
a_loss 0.861 c_loss 0.002 b_loss 0.000
a_loss 0.849 c_loss 0.002 b_loss 0.000
epoch num: 87
fps step: 1484 fps step and policy inference: 1425 fps total: 1414 epoch: 87/100000
epoch: 87 mean_rewards: [295.28] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.898 c_loss 0.002 b_loss 0.000
a_loss 0.891 c_loss 0.002 b_loss 0.000
a_loss 0.881 c_loss 0.002 b_loss 0.000
a_loss 0.872 c_loss 0.002 b_loss 0.000
a_loss 0.859 c_loss 0.002 b_loss 0.000
a_loss 0.846 c_loss 0.002 b_loss 0.000
epoch num: 88
fps step: 1492 fps step and policy inference: 1431 fps total: 1420 epoch: 88/100000
epoch: 88 mean_rewards: [293.67] mean_lengths: 298.9506
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.899 c_loss 0.002 b_loss 0.000
a_loss 0.892 c_loss 0.002 b_loss 0.000
a_loss 0.884 c_loss 0.002 b_loss 0.000
a_loss 0.875 c_loss 0.002 b_loss 0.000
a_loss 0.862 c_loss 0.002 b_loss 0.000
a_loss 0.849 c_loss 0.002 b_loss 0.000
epoch num: 89
fps step: 1474 fps step and policy inference: 1417 fps total: 1406 epoch: 89/100000
epoch: 89 mean_rewards: [293.67] mean_lengths: 298.9506
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.857 c_loss 0.002 b_loss 0.000
a_loss 0.851 c_loss 0.002 b_loss 0.000
a_loss 0.844 c_loss 0.002 b_loss 0.000
a_loss 0.836 c_loss 0.002 b_loss 0.000
a_loss 0.824 c_loss 0.002 b_loss 0.000
a_loss 0.811 c_loss 0.002 b_loss 0.000
epoch num: 90
fps step: 1484 fps step and policy inference: 1418 fps total: 1407 epoch: 90/100000
epoch: 90 mean_rewards: [293.89] mean_lengths: 297.07
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.900 c_loss 0.002 b_loss 0.000
a_loss 0.894 c_loss 0.002 b_loss 0.000
a_loss 0.886 c_loss 0.002 b_loss 0.000
a_loss 0.875 c_loss 0.002 b_loss 0.000
a_loss 0.862 c_loss 0.002 b_loss 0.000
a_loss 0.848 c_loss 0.002 b_loss 0.000
epoch num: 91
fps step: 1457 fps step and policy inference: 1400 fps total: 1390 epoch: 91/100000
epoch: 91 mean_rewards: [293.89] mean_lengths: 297.07
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.898 c_loss 0.002 b_loss 0.000
a_loss 0.892 c_loss 0.002 b_loss 0.000
a_loss 0.883 c_loss 0.002 b_loss 0.000
a_loss 0.873 c_loss 0.002 b_loss 0.000
a_loss 0.861 c_loss 0.002 b_loss 0.000
a_loss 0.848 c_loss 0.002 b_loss 0.000
epoch num: 92
fps step: 1469 fps step and policy inference: 1410 fps total: 1399 epoch: 92/100000
epoch: 92 mean_rewards: [293.94] mean_lengths: 297.0993
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.898 c_loss 0.002 b_loss 0.000
a_loss 0.892 c_loss 0.002 b_loss 0.000
a_loss 0.883 c_loss 0.002 b_loss 0.000
a_loss 0.874 c_loss 0.002 b_loss 0.000
a_loss 0.861 c_loss 0.002 b_loss 0.000
a_loss 0.848 c_loss 0.002 b_loss 0.000
epoch num: 93
fps step: 1484 fps step and policy inference: 1425 fps total: 1414 epoch: 93/100000
epoch: 93 mean_rewards: [293.55] mean_lengths: 297.15704
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.841 c_loss 0.002 b_loss 0.000
a_loss 0.835 c_loss 0.002 b_loss 0.000
a_loss 0.828 c_loss 0.002 b_loss 0.000
a_loss 0.819 c_loss 0.002 b_loss 0.000
a_loss 0.807 c_loss 0.002 b_loss 0.000
a_loss 0.794 c_loss 0.002 b_loss 0.000
epoch num: 94
fps step: 1484 fps step and policy inference: 1419 fps total: 1408 epoch: 94/100000
epoch: 94 mean_rewards: [291.45] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.900 c_loss 0.002 b_loss 0.000
a_loss 0.893 c_loss 0.002 b_loss 0.000
a_loss 0.884 c_loss 0.002 b_loss 0.000
a_loss 0.875 c_loss 0.002 b_loss 0.000
a_loss 0.863 c_loss 0.002 b_loss 0.000
a_loss 0.850 c_loss 0.002 b_loss 0.000
epoch num: 95
fps step: 1489 fps step and policy inference: 1430 fps total: 1419 epoch: 95/100000
epoch: 95 mean_rewards: [291.45] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.900 c_loss 0.002 b_loss 0.000
a_loss 0.894 c_loss 0.002 b_loss 0.000
a_loss 0.886 c_loss 0.002 b_loss 0.000
a_loss 0.877 c_loss 0.002 b_loss 0.000
a_loss 0.863 c_loss 0.002 b_loss 0.000
a_loss 0.850 c_loss 0.002 b_loss 0.000
epoch num: 96
fps step: 1457 fps step and policy inference: 1401 fps total: 1390 epoch: 96/100000
epoch: 96 mean_rewards: [291.45] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.899 c_loss 0.002 b_loss 0.000
a_loss 0.892 c_loss 0.002 b_loss 0.000
a_loss 0.884 c_loss 0.002 b_loss 0.000
a_loss 0.875 c_loss 0.002 b_loss 0.000
a_loss 0.861 c_loss 0.002 b_loss 0.000
a_loss 0.848 c_loss 0.002 b_loss 0.000
epoch num: 97
fps step: 1491 fps step and policy inference: 1431 fps total: 1420 epoch: 97/100000
epoch: 97 mean_rewards: [291.64] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.901 c_loss 0.002 b_loss 0.000
a_loss 0.894 c_loss 0.002 b_loss 0.000
a_loss 0.885 c_loss 0.002 b_loss 0.000
a_loss 0.875 c_loss 0.002 b_loss 0.000
a_loss 0.863 c_loss 0.002 b_loss 0.000
a_loss 0.850 c_loss 0.002 b_loss 0.000
epoch num: 98
fps step: 1472 fps step and policy inference: 1414 fps total: 1403 epoch: 98/100000
epoch: 98 mean_rewards: [291.46] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.857 c_loss 0.002 b_loss 0.000
a_loss 0.851 c_loss 0.002 b_loss 0.000
a_loss 0.843 c_loss 0.002 b_loss 0.000
a_loss 0.834 c_loss 0.002 b_loss 0.000
a_loss 0.823 c_loss 0.002 b_loss 0.000
a_loss 0.810 c_loss 0.002 b_loss 0.000
epoch num: 99
fps step: 1481 fps step and policy inference: 1415 fps total: 1404 epoch: 99/100000
epoch: 99 mean_rewards: [298.49] mean_lengths: 300.0
saving next best rewards:  [298.49]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.899 c_loss 0.002 b_loss 0.000
a_loss 0.893 c_loss 0.002 b_loss 0.000
a_loss 0.884 c_loss 0.002 b_loss 0.000
a_loss 0.875 c_loss 0.002 b_loss 0.000
a_loss 0.862 c_loss 0.002 b_loss 0.000
a_loss 0.848 c_loss 0.002 b_loss 0.000
epoch num: 100
fps step: 1471 fps step and policy inference: 1413 fps total: 1402 epoch: 100/100000
epoch: 100 mean_rewards: [298.49] mean_lengths: 300.0
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/last_Humanoid_ep_100_rew_298.4892.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.901 c_loss 0.002 b_loss 0.000
a_loss 0.894 c_loss 0.002 b_loss 0.000
a_loss 0.885 c_loss 0.002 b_loss 0.000
a_loss 0.876 c_loss 0.002 b_loss 0.000
a_loss 0.864 c_loss 0.002 b_loss 0.000
a_loss 0.851 c_loss 0.002 b_loss 0.000
epoch num: 101
fps step: 1431 fps step and policy inference: 1378 fps total: 1367 epoch: 101/100000
epoch: 101 mean_rewards: [298.49] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.899 c_loss 0.002 b_loss 0.000
a_loss 0.892 c_loss 0.002 b_loss 0.000
a_loss 0.884 c_loss 0.002 b_loss 0.000
a_loss 0.874 c_loss 0.002 b_loss 0.000
a_loss 0.862 c_loss 0.002 b_loss 0.000
a_loss 0.848 c_loss 0.002 b_loss 0.000
epoch num: 102
fps step: 1423 fps step and policy inference: 1366 fps total: 1356 epoch: 102/100000
epoch: 102 mean_rewards: [298.08] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.901 c_loss 0.002 b_loss 0.000
a_loss 0.895 c_loss 0.002 b_loss 0.000
a_loss 0.886 c_loss 0.002 b_loss 0.000
a_loss 0.876 c_loss 0.002 b_loss 0.000
a_loss 0.863 c_loss 0.002 b_loss 0.000
a_loss 0.850 c_loss 0.002 b_loss 0.000
epoch num: 103
fps step: 1432 fps step and policy inference: 1376 fps total: 1366 epoch: 103/100000
epoch: 103 mean_rewards: [297.69] mean_lengths: 299.82
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.844 c_loss 0.002 b_loss 0.000
a_loss 0.838 c_loss 0.002 b_loss 0.000
a_loss 0.830 c_loss 0.002 b_loss 0.000
a_loss 0.822 c_loss 0.002 b_loss 0.000
a_loss 0.811 c_loss 0.002 b_loss 0.000
a_loss 0.799 c_loss 0.002 b_loss 0.000
epoch num: 104
fps step: 1477 fps step and policy inference: 1411 fps total: 1401 epoch: 104/100000
epoch: 104 mean_rewards: [289.3] mean_lengths: 297.08
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.899 c_loss 0.002 b_loss 0.000
a_loss 0.893 c_loss 0.002 b_loss 0.000
a_loss 0.884 c_loss 0.002 b_loss 0.000
a_loss 0.874 c_loss 0.002 b_loss 0.000
a_loss 0.861 c_loss 0.002 b_loss 0.000
a_loss 0.848 c_loss 0.002 b_loss 0.000
epoch num: 105
fps step: 1476 fps step and policy inference: 1417 fps total: 1407 epoch: 105/100000
epoch: 105 mean_rewards: [287.14] mean_lengths: 294.91916
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.002 b_loss 0.000
a_loss 0.895 c_loss 0.002 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.865 c_loss 0.001 b_loss 0.000
a_loss 0.852 c_loss 0.001 b_loss 0.000
epoch num: 106
fps step: 1491 fps step and policy inference: 1432 fps total: 1420 epoch: 106/100000
epoch: 106 mean_rewards: [287.09] mean_lengths: 294.96994
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.901 c_loss 0.001 b_loss 0.000
a_loss 0.895 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.877 c_loss 0.001 b_loss 0.000
a_loss 0.865 c_loss 0.001 b_loss 0.000
a_loss 0.852 c_loss 0.001 b_loss 0.000
epoch num: 107
fps step: 1503 fps step and policy inference: 1442 fps total: 1430 epoch: 107/100000
epoch: 107 mean_rewards: [287.48] mean_lengths: 295.07004
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.841 c_loss 0.002 b_loss 0.000
a_loss 0.836 c_loss 0.002 b_loss 0.000
a_loss 0.828 c_loss 0.002 b_loss 0.000
a_loss 0.819 c_loss 0.002 b_loss 0.000
a_loss 0.809 c_loss 0.002 b_loss 0.000
a_loss 0.797 c_loss 0.002 b_loss 0.000
epoch num: 108
fps step: 1458 fps step and policy inference: 1392 fps total: 1381 epoch: 108/100000
epoch: 108 mean_rewards: [297.99] mean_lengths: 299.99997
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.002 b_loss 0.000
a_loss 0.897 c_loss 0.002 b_loss 0.000
a_loss 0.888 c_loss 0.002 b_loss 0.000
a_loss 0.878 c_loss 0.002 b_loss 0.000
a_loss 0.865 c_loss 0.001 b_loss 0.000
a_loss 0.852 c_loss 0.001 b_loss 0.000
epoch num: 109
fps step: 1497 fps step and policy inference: 1438 fps total: 1426 epoch: 109/100000
epoch: 109 mean_rewards: [297.99] mean_lengths: 299.99997
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.901 c_loss 0.001 b_loss 0.000
a_loss 0.895 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.865 c_loss 0.001 b_loss 0.000
a_loss 0.851 c_loss 0.001 b_loss 0.000
epoch num: 110
fps step: 1469 fps step and policy inference: 1411 fps total: 1400 epoch: 110/100000
epoch: 110 mean_rewards: [297.85] mean_lengths: 299.99997
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.886 c_loss 0.001 b_loss 0.000
a_loss 0.875 c_loss 0.001 b_loss 0.000
a_loss 0.862 c_loss 0.001 b_loss 0.000
a_loss 0.850 c_loss 0.001 b_loss 0.000
epoch num: 111
fps step: 1490 fps step and policy inference: 1430 fps total: 1419 epoch: 111/100000
epoch: 111 mean_rewards: [297.77] mean_lengths: 299.99997
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.901 c_loss 0.001 b_loss 0.000
a_loss 0.894 c_loss 0.001 b_loss 0.000
a_loss 0.885 c_loss 0.001 b_loss 0.000
a_loss 0.876 c_loss 0.001 b_loss 0.000
a_loss 0.864 c_loss 0.001 b_loss 0.000
a_loss 0.851 c_loss 0.001 b_loss 0.000
epoch num: 112
fps step: 1489 fps step and policy inference: 1430 fps total: 1419 epoch: 112/100000
epoch: 112 mean_rewards: [297.58] mean_lengths: 299.99997
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.858 c_loss 0.002 b_loss 0.000
a_loss 0.852 c_loss 0.002 b_loss 0.000
a_loss 0.843 c_loss 0.002 b_loss 0.000
a_loss 0.834 c_loss 0.002 b_loss 0.000
a_loss 0.823 c_loss 0.002 b_loss 0.000
a_loss 0.811 c_loss 0.002 b_loss 0.000
epoch num: 113
fps step: 1484 fps step and policy inference: 1416 fps total: 1405 epoch: 113/100000
epoch: 113 mean_rewards: [300.9] mean_lengths: 299.99997
saving next best rewards:  [300.9]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.901 c_loss 0.001 b_loss 0.000
a_loss 0.895 c_loss 0.001 b_loss 0.000
a_loss 0.886 c_loss 0.001 b_loss 0.000
a_loss 0.876 c_loss 0.001 b_loss 0.000
a_loss 0.864 c_loss 0.001 b_loss 0.000
a_loss 0.851 c_loss 0.001 b_loss 0.000
epoch num: 114
fps step: 1426 fps step and policy inference: 1372 fps total: 1362 epoch: 114/100000
epoch: 114 mean_rewards: [300.6] mean_lengths: 299.99997
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.877 c_loss 0.001 b_loss 0.000
a_loss 0.864 c_loss 0.001 b_loss 0.000
a_loss 0.851 c_loss 0.001 b_loss 0.000
epoch num: 115
fps step: 1391 fps step and policy inference: 1339 fps total: 1329 epoch: 115/100000
epoch: 115 mean_rewards: [300.6] mean_lengths: 299.99997
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.901 c_loss 0.001 b_loss 0.000
a_loss 0.894 c_loss 0.001 b_loss 0.000
a_loss 0.885 c_loss 0.001 b_loss 0.000
a_loss 0.876 c_loss 0.001 b_loss 0.000
a_loss 0.864 c_loss 0.001 b_loss 0.000
a_loss 0.851 c_loss 0.001 b_loss 0.000
epoch num: 116
fps step: 1410 fps step and policy inference: 1357 fps total: 1347 epoch: 116/100000
epoch: 116 mean_rewards: [299.83] mean_lengths: 299.99997
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.901 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.865 c_loss 0.001 b_loss 0.000
a_loss 0.852 c_loss 0.001 b_loss 0.000
epoch num: 117
fps step: 1418 fps step and policy inference: 1364 fps total: 1354 epoch: 117/100000
epoch: 117 mean_rewards: [299.4] mean_lengths: 299.99997
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.845 c_loss 0.002 b_loss 0.000
a_loss 0.839 c_loss 0.002 b_loss 0.000
a_loss 0.832 c_loss 0.002 b_loss 0.000
a_loss 0.823 c_loss 0.002 b_loss 0.000
a_loss 0.812 c_loss 0.002 b_loss 0.000
a_loss 0.800 c_loss 0.002 b_loss 0.000
epoch num: 118
fps step: 1487 fps step and policy inference: 1421 fps total: 1409 epoch: 118/100000
epoch: 118 mean_rewards: [290.88] mean_lengths: 297.07996
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.900 c_loss 0.001 b_loss 0.000
a_loss 0.894 c_loss 0.001 b_loss 0.000
a_loss 0.884 c_loss 0.001 b_loss 0.000
a_loss 0.875 c_loss 0.001 b_loss 0.000
a_loss 0.862 c_loss 0.001 b_loss 0.000
a_loss 0.849 c_loss 0.001 b_loss 0.000
epoch num: 119
fps step: 1467 fps step and policy inference: 1409 fps total: 1398 epoch: 119/100000
epoch: 119 mean_rewards: [291.12] mean_lengths: 297.10916
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 120
fps step: 1490 fps step and policy inference: 1431 fps total: 1420 epoch: 120/100000
epoch: 120 mean_rewards: [291.3] mean_lengths: 297.13806
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
epoch num: 121
fps step: 1486 fps step and policy inference: 1425 fps total: 1414 epoch: 121/100000
epoch: 121 mean_rewards: [291.86] mean_lengths: 297.195
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.850 c_loss 0.001 b_loss 0.000
a_loss 0.845 c_loss 0.001 b_loss 0.000
a_loss 0.837 c_loss 0.001 b_loss 0.000
a_loss 0.828 c_loss 0.001 b_loss 0.000
a_loss 0.816 c_loss 0.001 b_loss 0.000
a_loss 0.803 c_loss 0.001 b_loss 0.000
epoch num: 122
fps step: 1490 fps step and policy inference: 1423 fps total: 1412 epoch: 122/100000
epoch: 122 mean_rewards: [295.22] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.895 c_loss 0.001 b_loss 0.000
a_loss 0.886 c_loss 0.001 b_loss 0.000
a_loss 0.877 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
epoch num: 123
fps step: 1522 fps step and policy inference: 1461 fps total: 1449 epoch: 123/100000
epoch: 123 mean_rewards: [291.79] mean_lengths: 297.00998
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.852 c_loss 0.001 b_loss 0.000
epoch num: 124
fps step: 1434 fps step and policy inference: 1379 fps total: 1368 epoch: 124/100000
epoch: 124 mean_rewards: [291.94] mean_lengths: 297.0399
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.895 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.865 c_loss 0.001 b_loss 0.000
a_loss 0.852 c_loss 0.001 b_loss 0.000
epoch num: 125
fps step: 1401 fps step and policy inference: 1347 fps total: 1337 epoch: 125/100000
epoch: 125 mean_rewards: [291.97] mean_lengths: 297.0988
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.901 c_loss 0.001 b_loss 0.000
a_loss 0.895 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.877 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
epoch num: 126
fps step: 1396 fps step and policy inference: 1345 fps total: 1336 epoch: 126/100000
epoch: 126 mean_rewards: [292.02] mean_lengths: 297.12778
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.859 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
a_loss 0.844 c_loss 0.001 b_loss 0.000
a_loss 0.835 c_loss 0.001 b_loss 0.000
a_loss 0.824 c_loss 0.001 b_loss 0.000
a_loss 0.812 c_loss 0.001 b_loss 0.000
epoch num: 127
fps step: 1427 fps step and policy inference: 1365 fps total: 1355 epoch: 127/100000
epoch: 127 mean_rewards: [294.23] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.877 c_loss 0.001 b_loss 0.000
a_loss 0.865 c_loss 0.001 b_loss 0.000
a_loss 0.852 c_loss 0.001 b_loss 0.000
epoch num: 128
fps step: 1468 fps step and policy inference: 1411 fps total: 1400 epoch: 128/100000
epoch: 128 mean_rewards: [295.12] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.865 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
epoch num: 129
fps step: 1482 fps step and policy inference: 1425 fps total: 1414 epoch: 129/100000
epoch: 129 mean_rewards: [295.12] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.901 c_loss 0.001 b_loss 0.000
a_loss 0.895 c_loss 0.001 b_loss 0.000
a_loss 0.886 c_loss 0.001 b_loss 0.000
a_loss 0.876 c_loss 0.001 b_loss 0.000
a_loss 0.863 c_loss 0.001 b_loss 0.000
a_loss 0.851 c_loss 0.001 b_loss 0.000
epoch num: 130
fps step: 1509 fps step and policy inference: 1447 fps total: 1436 epoch: 130/100000
epoch: 130 mean_rewards: [295.55] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.895 c_loss 0.001 b_loss 0.000
a_loss 0.886 c_loss 0.001 b_loss 0.000
a_loss 0.876 c_loss 0.001 b_loss 0.000
a_loss 0.864 c_loss 0.001 b_loss 0.000
a_loss 0.851 c_loss 0.001 b_loss 0.000
epoch num: 131
fps step: 1477 fps step and policy inference: 1418 fps total: 1407 epoch: 131/100000
epoch: 131 mean_rewards: [295.81] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.848 c_loss 0.001 b_loss 0.000
a_loss 0.842 c_loss 0.001 b_loss 0.000
a_loss 0.835 c_loss 0.001 b_loss 0.000
a_loss 0.827 c_loss 0.001 b_loss 0.000
a_loss 0.817 c_loss 0.001 b_loss 0.000
a_loss 0.805 c_loss 0.001 b_loss 0.000
epoch num: 132
fps step: 1487 fps step and policy inference: 1421 fps total: 1410 epoch: 132/100000
epoch: 132 mean_rewards: [292.33] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
epoch num: 133
fps step: 1444 fps step and policy inference: 1388 fps total: 1378 epoch: 133/100000
epoch: 133 mean_rewards: [292.32] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.877 c_loss 0.001 b_loss 0.000
a_loss 0.865 c_loss 0.001 b_loss 0.000
a_loss 0.852 c_loss 0.001 b_loss 0.000
epoch num: 134
fps step: 1446 fps step and policy inference: 1391 fps total: 1381 epoch: 134/100000
epoch: 134 mean_rewards: [292.27] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 135
fps step: 1501 fps step and policy inference: 1440 fps total: 1428 epoch: 135/100000
epoch: 135 mean_rewards: [292.28] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.873 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.859 c_loss 0.001 b_loss 0.000
a_loss 0.850 c_loss 0.001 b_loss 0.000
a_loss 0.838 c_loss 0.001 b_loss 0.000
a_loss 0.825 c_loss 0.001 b_loss 0.000
epoch num: 136
fps step: 1490 fps step and policy inference: 1426 fps total: 1415 epoch: 136/100000
epoch: 136 mean_rewards: [298.07] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 137
fps step: 1492 fps step and policy inference: 1431 fps total: 1419 epoch: 137/100000
epoch: 137 mean_rewards: [297.54] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 138
fps step: 1467 fps step and policy inference: 1410 fps total: 1399 epoch: 138/100000
epoch: 138 mean_rewards: [297.45] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 139
fps step: 1485 fps step and policy inference: 1424 fps total: 1413 epoch: 139/100000
epoch: 139 mean_rewards: [297.19] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 140
fps step: 1482 fps step and policy inference: 1423 fps total: 1412 epoch: 140/100000
epoch: 140 mean_rewards: [297.74] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.853 c_loss 0.001 b_loss 0.000
a_loss 0.847 c_loss 0.001 b_loss 0.000
a_loss 0.839 c_loss 0.001 b_loss 0.000
a_loss 0.831 c_loss 0.001 b_loss 0.000
a_loss 0.821 c_loss 0.001 b_loss 0.000
a_loss 0.809 c_loss 0.001 b_loss 0.000
epoch num: 141
fps step: 1487 fps step and policy inference: 1419 fps total: 1408 epoch: 141/100000
epoch: 141 mean_rewards: [299.2] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
epoch num: 142
fps step: 1475 fps step and policy inference: 1417 fps total: 1407 epoch: 142/100000
epoch: 142 mean_rewards: [299.08] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 143
fps step: 1448 fps step and policy inference: 1393 fps total: 1383 epoch: 143/100000
epoch: 143 mean_rewards: [299.08] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.895 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
epoch num: 144
fps step: 1411 fps step and policy inference: 1355 fps total: 1345 epoch: 144/100000
epoch: 144 mean_rewards: [297.93] mean_lengths: 298.69318
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 145
fps step: 1435 fps step and policy inference: 1380 fps total: 1370 epoch: 145/100000
epoch: 145 mean_rewards: [297.67] mean_lengths: 298.70624
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.850 c_loss 0.001 b_loss 0.000
a_loss 0.844 c_loss 0.001 b_loss 0.000
a_loss 0.836 c_loss 0.001 b_loss 0.000
a_loss 0.827 c_loss 0.001 b_loss 0.000
a_loss 0.816 c_loss 0.001 b_loss 0.000
a_loss 0.804 c_loss 0.001 b_loss 0.000
epoch num: 146
fps step: 1481 fps step and policy inference: 1415 fps total: 1404 epoch: 146/100000
epoch: 146 mean_rewards: [299.9] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.901 c_loss 0.001 b_loss 0.000
a_loss 0.894 c_loss 0.001 b_loss 0.000
a_loss 0.886 c_loss 0.001 b_loss 0.000
a_loss 0.877 c_loss 0.001 b_loss 0.000
a_loss 0.865 c_loss 0.001 b_loss 0.000
a_loss 0.852 c_loss 0.001 b_loss 0.000
epoch num: 147
fps step: 1450 fps step and policy inference: 1394 fps total: 1384 epoch: 147/100000
epoch: 147 mean_rewards: [299.57] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.895 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 148
fps step: 1482 fps step and policy inference: 1423 fps total: 1412 epoch: 148/100000
epoch: 148 mean_rewards: [299.44] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 149
fps step: 1496 fps step and policy inference: 1435 fps total: 1424 epoch: 149/100000
epoch: 149 mean_rewards: [299.14] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.870 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 150
fps step: 1451 fps step and policy inference: 1394 fps total: 1384 epoch: 150/100000
epoch: 150 mean_rewards: [299.1] mean_lengths: 300.0
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/last_Humanoid_ep_150_rew_299.1.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.892 c_loss 0.001 b_loss 0.000
a_loss 0.886 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
a_loss 0.844 c_loss 0.001 b_loss 0.000
epoch num: 151
fps step: 1495 fps step and policy inference: 1428 fps total: 1417 epoch: 151/100000
epoch: 151 mean_rewards: [307.46] mean_lengths: 300.0
saving next best rewards:  [307.46]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 152
fps step: 1479 fps step and policy inference: 1420 fps total: 1409 epoch: 152/100000
epoch: 152 mean_rewards: [307.81] mean_lengths: 300.0
saving next best rewards:  [307.81]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 153
fps step: 1459 fps step and policy inference: 1401 fps total: 1390 epoch: 153/100000
epoch: 153 mean_rewards: [307.69] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.891 c_loss 0.001 b_loss 0.000
a_loss 0.882 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 154
fps step: 1496 fps step and policy inference: 1435 fps total: 1424 epoch: 154/100000
epoch: 154 mean_rewards: [307.27] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.849 c_loss 0.001 b_loss 0.000
a_loss 0.843 c_loss 0.001 b_loss 0.000
a_loss 0.836 c_loss 0.001 b_loss 0.000
a_loss 0.827 c_loss 0.001 b_loss 0.000
a_loss 0.816 c_loss 0.001 b_loss 0.000
a_loss 0.804 c_loss 0.001 b_loss 0.000
epoch num: 155
fps step: 1478 fps step and policy inference: 1412 fps total: 1401 epoch: 155/100000
epoch: 155 mean_rewards: [301.29] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 156
fps step: 1493 fps step and policy inference: 1434 fps total: 1423 epoch: 156/100000
epoch: 156 mean_rewards: [302.] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 157
fps step: 1483 fps step and policy inference: 1426 fps total: 1415 epoch: 157/100000
epoch: 157 mean_rewards: [302.] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 158
fps step: 1503 fps step and policy inference: 1441 fps total: 1430 epoch: 158/100000
epoch: 158 mean_rewards: [301.75] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 159
fps step: 1468 fps step and policy inference: 1411 fps total: 1400 epoch: 159/100000
epoch: 159 mean_rewards: [301.33] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.860 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
a_loss 0.846 c_loss 0.001 b_loss 0.000
a_loss 0.838 c_loss 0.001 b_loss 0.000
a_loss 0.827 c_loss 0.001 b_loss 0.000
a_loss 0.814 c_loss 0.001 b_loss 0.000
epoch num: 160
fps step: 1496 fps step and policy inference: 1429 fps total: 1418 epoch: 160/100000
epoch: 160 mean_rewards: [306.35] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.877 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 161
fps step: 1430 fps step and policy inference: 1375 fps total: 1365 epoch: 161/100000
epoch: 161 mean_rewards: [303.97] mean_lengths: 297.85
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 162
fps step: 1486 fps step and policy inference: 1426 fps total: 1415 epoch: 162/100000
epoch: 162 mean_rewards: [304.08] mean_lengths: 297.8715
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 163
fps step: 1471 fps step and policy inference: 1412 fps total: 1401 epoch: 163/100000
epoch: 163 mean_rewards: [303.51] mean_lengths: 297.9347
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 164
fps step: 1495 fps step and policy inference: 1435 fps total: 1424 epoch: 164/100000
epoch: 164 mean_rewards: [303.21] mean_lengths: 297.95535
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.848 c_loss 0.001 b_loss 0.000
a_loss 0.842 c_loss 0.001 b_loss 0.000
a_loss 0.835 c_loss 0.001 b_loss 0.000
a_loss 0.827 c_loss 0.001 b_loss 0.000
a_loss 0.816 c_loss 0.001 b_loss 0.000
a_loss 0.804 c_loss 0.001 b_loss 0.000
epoch num: 165
fps step: 1502 fps step and policy inference: 1434 fps total: 1423 epoch: 165/100000
epoch: 165 mean_rewards: [300.7] mean_lengths: 297.15002
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.901 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.876 c_loss 0.001 b_loss 0.000
a_loss 0.864 c_loss 0.001 b_loss 0.000
a_loss 0.852 c_loss 0.001 b_loss 0.000
epoch num: 166
fps step: 1486 fps step and policy inference: 1427 fps total: 1416 epoch: 166/100000
epoch: 166 mean_rewards: [300.91] mean_lengths: 297.20673
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.900 c_loss 0.001 b_loss 0.000
a_loss 0.893 c_loss 0.001 b_loss 0.000
a_loss 0.884 c_loss 0.001 b_loss 0.000
a_loss 0.875 c_loss 0.001 b_loss 0.000
a_loss 0.863 c_loss 0.001 b_loss 0.000
a_loss 0.850 c_loss 0.001 b_loss 0.000
epoch num: 167
fps step: 1511 fps step and policy inference: 1448 fps total: 1437 epoch: 167/100000
epoch: 167 mean_rewards: [300.01] mean_lengths: 295.78033
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.901 c_loss 0.001 b_loss 0.000
a_loss 0.895 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.877 c_loss 0.001 b_loss 0.000
a_loss 0.865 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
epoch num: 168
fps step: 1507 fps step and policy inference: 1445 fps total: 1434 epoch: 168/100000
epoch: 168 mean_rewards: [299.68] mean_lengths: 295.86432
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.846 c_loss 0.001 b_loss 0.000
a_loss 0.841 c_loss 0.001 b_loss 0.000
a_loss 0.832 c_loss 0.001 b_loss 0.000
a_loss 0.824 c_loss 0.001 b_loss 0.000
a_loss 0.813 c_loss 0.001 b_loss 0.000
a_loss 0.801 c_loss 0.001 b_loss 0.000
epoch num: 169
fps step: 1472 fps step and policy inference: 1405 fps total: 1395 epoch: 169/100000
epoch: 169 mean_rewards: [299.06] mean_lengths: 294.27698
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.886 c_loss 0.001 b_loss 0.000
a_loss 0.877 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 170
fps step: 1480 fps step and policy inference: 1422 fps total: 1411 epoch: 170/100000
epoch: 170 mean_rewards: [296.08] mean_lengths: 291.3442
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 171
fps step: 1476 fps step and policy inference: 1417 fps total: 1406 epoch: 171/100000
epoch: 171 mean_rewards: [296.6] mean_lengths: 291.51645
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
epoch num: 172
fps step: 1491 fps step and policy inference: 1428 fps total: 1417 epoch: 172/100000
epoch: 172 mean_rewards: [295.55] mean_lengths: 290.49615
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 173
fps step: 1445 fps step and policy inference: 1390 fps total: 1379 epoch: 173/100000
epoch: 173 mean_rewards: [295.68] mean_lengths: 290.5912
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.860 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
a_loss 0.846 c_loss 0.001 b_loss 0.000
a_loss 0.837 c_loss 0.001 b_loss 0.000
a_loss 0.826 c_loss 0.001 b_loss 0.000
a_loss 0.815 c_loss 0.001 b_loss 0.000
epoch num: 174
fps step: 1469 fps step and policy inference: 1401 fps total: 1390 epoch: 174/100000
epoch: 174 mean_rewards: [306.92] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 175
fps step: 1486 fps step and policy inference: 1427 fps total: 1416 epoch: 175/100000
epoch: 175 mean_rewards: [306.87] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
epoch num: 176
fps step: 1459 fps step and policy inference: 1402 fps total: 1391 epoch: 176/100000
epoch: 176 mean_rewards: [306.79] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
epoch num: 177
fps step: 1439 fps step and policy inference: 1381 fps total: 1370 epoch: 177/100000
epoch: 177 mean_rewards: [306.11] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 178
fps step: 1493 fps step and policy inference: 1433 fps total: 1422 epoch: 178/100000
epoch: 178 mean_rewards: [305.86] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.848 c_loss 0.001 b_loss 0.000
a_loss 0.843 c_loss 0.001 b_loss 0.000
a_loss 0.835 c_loss 0.001 b_loss 0.000
a_loss 0.826 c_loss 0.001 b_loss 0.000
a_loss 0.816 c_loss 0.001 b_loss 0.000
a_loss 0.804 c_loss 0.001 b_loss 0.000
epoch num: 179
fps step: 1520 fps step and policy inference: 1448 fps total: 1436 epoch: 179/100000
epoch: 179 mean_rewards: [301.15] mean_lengths: 294.41956
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 180
fps step: 1495 fps step and policy inference: 1435 fps total: 1424 epoch: 180/100000
epoch: 180 mean_rewards: [300.46] mean_lengths: 294.53058
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 181
fps step: 1507 fps step and policy inference: 1443 fps total: 1432 epoch: 181/100000
epoch: 181 mean_rewards: [299.93] mean_lengths: 294.74606
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 182
fps step: 1486 fps step and policy inference: 1427 fps total: 1416 epoch: 182/100000
epoch: 182 mean_rewards: [299.3] mean_lengths: 294.8506
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.848 c_loss 0.001 b_loss 0.000
a_loss 0.843 c_loss 0.001 b_loss 0.000
a_loss 0.834 c_loss 0.001 b_loss 0.000
a_loss 0.825 c_loss 0.001 b_loss 0.000
a_loss 0.814 c_loss 0.001 b_loss 0.000
a_loss 0.802 c_loss 0.001 b_loss 0.000
epoch num: 183
fps step: 1523 fps step and policy inference: 1451 fps total: 1439 epoch: 183/100000
epoch: 183 mean_rewards: [304.96] mean_lengths: 297.27032
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 184
fps step: 1480 fps step and policy inference: 1420 fps total: 1409 epoch: 184/100000
epoch: 184 mean_rewards: [302.33] mean_lengths: 294.39157
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 185
fps step: 1448 fps step and policy inference: 1391 fps total: 1380 epoch: 185/100000
epoch: 185 mean_rewards: [302.95] mean_lengths: 294.50317
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.895 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 186
fps step: 1447 fps step and policy inference: 1386 fps total: 1375 epoch: 186/100000
epoch: 186 mean_rewards: [302.72] mean_lengths: 293.26263
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 187
fps step: 1488 fps step and policy inference: 1429 fps total: 1418 epoch: 187/100000
epoch: 187 mean_rewards: [302.79] mean_lengths: 293.33
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.862 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
a_loss 0.849 c_loss 0.001 b_loss 0.000
a_loss 0.841 c_loss 0.001 b_loss 0.000
a_loss 0.830 c_loss 0.001 b_loss 0.000
a_loss 0.818 c_loss 0.001 b_loss 0.000
epoch num: 188
fps step: 1488 fps step and policy inference: 1417 fps total: 1406 epoch: 188/100000
epoch: 188 mean_rewards: [305.86] mean_lengths: 297.2617
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 189
fps step: 1464 fps step and policy inference: 1406 fps total: 1395 epoch: 189/100000
epoch: 189 mean_rewards: [305.64] mean_lengths: 297.31616
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 190
fps step: 1477 fps step and policy inference: 1417 fps total: 1406 epoch: 190/100000
epoch: 190 mean_rewards: [305.84] mean_lengths: 297.39584
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 191
fps step: 1484 fps step and policy inference: 1424 fps total: 1413 epoch: 191/100000
epoch: 191 mean_rewards: [305.61] mean_lengths: 297.47318
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 192
fps step: 1522 fps step and policy inference: 1460 fps total: 1448 epoch: 192/100000
epoch: 192 mean_rewards: [304.99] mean_lengths: 297.52344
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.848 c_loss 0.001 b_loss 0.000
a_loss 0.843 c_loss 0.001 b_loss 0.000
a_loss 0.834 c_loss 0.001 b_loss 0.000
a_loss 0.825 c_loss 0.001 b_loss 0.000
a_loss 0.815 c_loss 0.001 b_loss 0.000
a_loss 0.803 c_loss 0.001 b_loss 0.000
epoch num: 193
fps step: 1495 fps step and policy inference: 1425 fps total: 1414 epoch: 193/100000
epoch: 193 mean_rewards: [304.45] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 194
fps step: 1471 fps step and policy inference: 1411 fps total: 1400 epoch: 194/100000
epoch: 194 mean_rewards: [303.82] mean_lengths: 297.80222
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
epoch num: 195
fps step: 1456 fps step and policy inference: 1397 fps total: 1386 epoch: 195/100000
epoch: 195 mean_rewards: [303.77] mean_lengths: 297.90988
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 196
fps step: 1447 fps step and policy inference: 1390 fps total: 1379 epoch: 196/100000
epoch: 196 mean_rewards: [303.59] mean_lengths: 297.95148
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.856 c_loss 0.001 b_loss 0.000
a_loss 0.850 c_loss 0.001 b_loss 0.000
a_loss 0.842 c_loss 0.001 b_loss 0.000
a_loss 0.832 c_loss 0.001 b_loss 0.000
a_loss 0.821 c_loss 0.001 b_loss 0.000
a_loss 0.809 c_loss 0.001 b_loss 0.000
epoch num: 197
fps step: 1396 fps step and policy inference: 1333 fps total: 1323 epoch: 197/100000
epoch: 197 mean_rewards: [315.64] mean_lengths: 300.0
saving next best rewards:  [315.64]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.887 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 198
fps step: 1377 fps step and policy inference: 1320 fps total: 1309 epoch: 198/100000
epoch: 198 mean_rewards: [313.55] mean_lengths: 297.0698
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
epoch num: 199
fps step: 1362 fps step and policy inference: 1305 fps total: 1294 epoch: 199/100000
epoch: 199 mean_rewards: [311.71] mean_lengths: 295.38525
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.895 c_loss 0.001 b_loss 0.000
a_loss 0.886 c_loss 0.001 b_loss 0.000
a_loss 0.877 c_loss 0.001 b_loss 0.000
a_loss 0.865 c_loss 0.001 b_loss 0.000
a_loss 0.851 c_loss 0.001 b_loss 0.000
epoch num: 200
fps step: 1363 fps step and policy inference: 1305 fps total: 1294 epoch: 200/100000
epoch: 200 mean_rewards: [311.7] mean_lengths: 295.65527
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/last_Humanoid_ep_200_rew_311.69907.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 201
fps step: 1357 fps step and policy inference: 1302 fps total: 1292 epoch: 201/100000
epoch: 201 mean_rewards: [311.54] mean_lengths: 295.6987
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.860 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
a_loss 0.846 c_loss 0.001 b_loss 0.000
a_loss 0.838 c_loss 0.001 b_loss 0.000
a_loss 0.826 c_loss 0.001 b_loss 0.000
a_loss 0.813 c_loss 0.001 b_loss 0.000
epoch num: 202
fps step: 1391 fps step and policy inference: 1327 fps total: 1317 epoch: 202/100000
epoch: 202 mean_rewards: [310.57] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
epoch num: 203
fps step: 1457 fps step and policy inference: 1397 fps total: 1385 epoch: 203/100000
epoch: 203 mean_rewards: [311.24] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 204
fps step: 1455 fps step and policy inference: 1396 fps total: 1384 epoch: 204/100000
epoch: 204 mean_rewards: [310.55] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 205
fps step: 1422 fps step and policy inference: 1363 fps total: 1352 epoch: 205/100000
epoch: 205 mean_rewards: [307.12] mean_lengths: 297.0988
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 206
fps step: 1446 fps step and policy inference: 1388 fps total: 1376 epoch: 206/100000
epoch: 206 mean_rewards: [305.62] mean_lengths: 295.73953
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.851 c_loss 0.001 b_loss 0.000
a_loss 0.846 c_loss 0.001 b_loss 0.000
a_loss 0.838 c_loss 0.001 b_loss 0.000
a_loss 0.830 c_loss 0.001 b_loss 0.000
a_loss 0.819 c_loss 0.001 b_loss 0.000
a_loss 0.808 c_loss 0.001 b_loss 0.000
epoch num: 207
fps step: 1437 fps step and policy inference: 1371 fps total: 1359 epoch: 207/100000
epoch: 207 mean_rewards: [302.6] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 208
fps step: 1416 fps step and policy inference: 1360 fps total: 1348 epoch: 208/100000
epoch: 208 mean_rewards: [302.29] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 209
fps step: 1345 fps step and policy inference: 1287 fps total: 1277 epoch: 209/100000
epoch: 209 mean_rewards: [301.93] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 210
fps step: 1404 fps step and policy inference: 1345 fps total: 1333 epoch: 210/100000
epoch: 210 mean_rewards: [302.11] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.877 c_loss 0.001 b_loss 0.000
a_loss 0.871 c_loss 0.001 b_loss 0.000
a_loss 0.863 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
a_loss 0.843 c_loss 0.001 b_loss 0.000
a_loss 0.831 c_loss 0.001 b_loss 0.000
epoch num: 211
fps step: 1454 fps step and policy inference: 1391 fps total: 1379 epoch: 211/100000
epoch: 211 mean_rewards: [316.92] mean_lengths: 300.0
saving next best rewards:  [316.92]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.895 c_loss 0.001 b_loss 0.000
a_loss 0.886 c_loss 0.001 b_loss 0.000
a_loss 0.877 c_loss 0.001 b_loss 0.000
a_loss 0.865 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
epoch num: 212
fps step: 1358 fps step and policy inference: 1297 fps total: 1286 epoch: 212/100000
epoch: 212 mean_rewards: [313.39] mean_lengths: 297.27216
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.891 c_loss 0.001 b_loss 0.000
a_loss 0.882 c_loss 0.001 b_loss 0.000
a_loss 0.870 c_loss 0.001 b_loss 0.000
a_loss 0.858 c_loss 0.001 b_loss 0.000
epoch num: 213
fps step: 1406 fps step and policy inference: 1348 fps total: 1336 epoch: 213/100000
epoch: 213 mean_rewards: [312.55] mean_lengths: 297.35318
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 214
fps step: 1388 fps step and policy inference: 1327 fps total: 1317 epoch: 214/100000
epoch: 214 mean_rewards: [313.4] mean_lengths: 297.50803
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 215
fps step: 1370 fps step and policy inference: 1313 fps total: 1302 epoch: 215/100000
epoch: 215 mean_rewards: [313.04] mean_lengths: 297.062
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.857 c_loss 0.001 b_loss 0.000
a_loss 0.851 c_loss 0.001 b_loss 0.000
a_loss 0.843 c_loss 0.001 b_loss 0.000
a_loss 0.835 c_loss 0.001 b_loss 0.000
a_loss 0.824 c_loss 0.001 b_loss 0.000
a_loss 0.812 c_loss 0.001 b_loss 0.000
epoch num: 216
fps step: 1452 fps step and policy inference: 1384 fps total: 1373 epoch: 216/100000
epoch: 216 mean_rewards: [314.25] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 217
fps step: 1474 fps step and policy inference: 1414 fps total: 1402 epoch: 217/100000
epoch: 217 mean_rewards: [314.73] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 218
fps step: 1463 fps step and policy inference: 1405 fps total: 1393 epoch: 218/100000
epoch: 218 mean_rewards: [314.05] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 219
fps step: 1440 fps step and policy inference: 1381 fps total: 1370 epoch: 219/100000
epoch: 219 mean_rewards: [313.66] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 220
fps step: 1463 fps step and policy inference: 1404 fps total: 1392 epoch: 220/100000
epoch: 220 mean_rewards: [314.42] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.856 c_loss 0.001 b_loss 0.000
a_loss 0.850 c_loss 0.001 b_loss 0.000
a_loss 0.843 c_loss 0.001 b_loss 0.000
a_loss 0.835 c_loss 0.001 b_loss 0.000
a_loss 0.824 c_loss 0.001 b_loss 0.000
a_loss 0.811 c_loss 0.001 b_loss 0.000
epoch num: 221
fps step: 1508 fps step and policy inference: 1436 fps total: 1423 epoch: 221/100000
epoch: 221 mean_rewards: [317.18] mean_lengths: 300.0
saving next best rewards:  [317.18]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 222
fps step: 1493 fps step and policy inference: 1432 fps total: 1419 epoch: 222/100000
epoch: 222 mean_rewards: [316.94] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 223
fps step: 1469 fps step and policy inference: 1406 fps total: 1394 epoch: 223/100000
epoch: 223 mean_rewards: [317.14] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 224
fps step: 1469 fps step and policy inference: 1410 fps total: 1397 epoch: 224/100000
epoch: 224 mean_rewards: [317.24] mean_lengths: 300.0
saving next best rewards:  [317.24]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 225
fps step: 1435 fps step and policy inference: 1378 fps total: 1367 epoch: 225/100000
epoch: 225 mean_rewards: [315.72] mean_lengths: 297.0695
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.891 c_loss 0.001 b_loss 0.000
a_loss 0.884 c_loss 0.001 b_loss 0.000
a_loss 0.875 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
a_loss 0.841 c_loss 0.001 b_loss 0.000
epoch num: 226
fps step: 1497 fps step and policy inference: 1428 fps total: 1415 epoch: 226/100000
epoch: 226 mean_rewards: [312.33] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 227
fps step: 1455 fps step and policy inference: 1396 fps total: 1384 epoch: 227/100000
epoch: 227 mean_rewards: [312.53] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 228
fps step: 1498 fps step and policy inference: 1434 fps total: 1422 epoch: 228/100000
epoch: 228 mean_rewards: [312.2] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 229
fps step: 1508 fps step and policy inference: 1444 fps total: 1432 epoch: 229/100000
epoch: 229 mean_rewards: [311.76] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.849 c_loss 0.001 b_loss 0.000
a_loss 0.842 c_loss 0.001 b_loss 0.000
a_loss 0.835 c_loss 0.001 b_loss 0.000
a_loss 0.827 c_loss 0.001 b_loss 0.000
a_loss 0.816 c_loss 0.001 b_loss 0.000
a_loss 0.803 c_loss 0.001 b_loss 0.000
epoch num: 230
fps step: 1524 fps step and policy inference: 1450 fps total: 1438 epoch: 230/100000
epoch: 230 mean_rewards: [300.93] mean_lengths: 294.45743
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.891 c_loss 0.001 b_loss 0.000
a_loss 0.882 c_loss 0.001 b_loss 0.000
a_loss 0.870 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 231
fps step: 1491 fps step and policy inference: 1433 fps total: 1421 epoch: 231/100000
epoch: 231 mean_rewards: [300.93] mean_lengths: 294.45743
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 232
fps step: 1452 fps step and policy inference: 1393 fps total: 1382 epoch: 232/100000
epoch: 232 mean_rewards: [301.83] mean_lengths: 294.6758
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 233
fps step: 1473 fps step and policy inference: 1411 fps total: 1399 epoch: 233/100000
epoch: 233 mean_rewards: [302.31] mean_lengths: 294.93674
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 234
fps step: 1504 fps step and policy inference: 1442 fps total: 1430 epoch: 234/100000
epoch: 234 mean_rewards: [302.12] mean_lengths: 295.08713
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.861 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
a_loss 0.847 c_loss 0.001 b_loss 0.000
a_loss 0.837 c_loss 0.001 b_loss 0.000
a_loss 0.826 c_loss 0.001 b_loss 0.000
a_loss 0.815 c_loss 0.001 b_loss 0.000
epoch num: 235
fps step: 1515 fps step and policy inference: 1442 fps total: 1429 epoch: 235/100000
epoch: 235 mean_rewards: [318.61] mean_lengths: 300.0
saving next best rewards:  [318.61]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 236
fps step: 1503 fps step and policy inference: 1442 fps total: 1430 epoch: 236/100000
epoch: 236 mean_rewards: [319.1] mean_lengths: 300.0
saving next best rewards:  [319.1]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 237
fps step: 1472 fps step and policy inference: 1409 fps total: 1397 epoch: 237/100000
epoch: 237 mean_rewards: [318.65] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 238
fps step: 1497 fps step and policy inference: 1436 fps total: 1424 epoch: 238/100000
epoch: 238 mean_rewards: [318.37] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 239
fps step: 1510 fps step and policy inference: 1447 fps total: 1435 epoch: 239/100000
epoch: 239 mean_rewards: [318.78] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.863 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
a_loss 0.849 c_loss 0.001 b_loss 0.000
a_loss 0.841 c_loss 0.001 b_loss 0.000
a_loss 0.830 c_loss 0.001 b_loss 0.000
a_loss 0.818 c_loss 0.001 b_loss 0.000
epoch num: 240
fps step: 1487 fps step and policy inference: 1416 fps total: 1405 epoch: 240/100000
epoch: 240 mean_rewards: [306.56] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 241
fps step: 1516 fps step and policy inference: 1453 fps total: 1441 epoch: 241/100000
epoch: 241 mean_rewards: [307.47] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 242
fps step: 1492 fps step and policy inference: 1429 fps total: 1417 epoch: 242/100000
epoch: 242 mean_rewards: [307.39] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 243
fps step: 1492 fps step and policy inference: 1429 fps total: 1417 epoch: 243/100000
epoch: 243 mean_rewards: [307.54] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.849 c_loss 0.001 b_loss 0.000
a_loss 0.844 c_loss 0.001 b_loss 0.000
a_loss 0.837 c_loss 0.001 b_loss 0.000
a_loss 0.828 c_loss 0.001 b_loss 0.000
a_loss 0.817 c_loss 0.001 b_loss 0.000
a_loss 0.805 c_loss 0.001 b_loss 0.000
epoch num: 244
fps step: 1496 fps step and policy inference: 1424 fps total: 1412 epoch: 244/100000
epoch: 244 mean_rewards: [312.24] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 245
fps step: 1486 fps step and policy inference: 1429 fps total: 1416 epoch: 245/100000
epoch: 245 mean_rewards: [312.24] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.891 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 246
fps step: 1478 fps step and policy inference: 1418 fps total: 1406 epoch: 246/100000
epoch: 246 mean_rewards: [312.68] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 247
fps step: 1487 fps step and policy inference: 1422 fps total: 1410 epoch: 247/100000
epoch: 247 mean_rewards: [311.09] mean_lengths: 298.94067
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 248
fps step: 1492 fps step and policy inference: 1430 fps total: 1418 epoch: 248/100000
epoch: 248 mean_rewards: [311.15] mean_lengths: 298.97214
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.863 c_loss 0.001 b_loss 0.000
a_loss 0.858 c_loss 0.001 b_loss 0.000
a_loss 0.850 c_loss 0.001 b_loss 0.000
a_loss 0.841 c_loss 0.001 b_loss 0.000
a_loss 0.831 c_loss 0.001 b_loss 0.000
a_loss 0.819 c_loss 0.001 b_loss 0.000
epoch num: 249
fps step: 1499 fps step and policy inference: 1426 fps total: 1413 epoch: 249/100000
epoch: 249 mean_rewards: [313.54] mean_lengths: 297.39694
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 250
fps step: 1435 fps step and policy inference: 1378 fps total: 1367 epoch: 250/100000
epoch: 250 mean_rewards: [311.26] mean_lengths: 295.44424
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/last_Humanoid_ep_250_rew_311.25766.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 251
fps step: 1428 fps step and policy inference: 1371 fps total: 1359 epoch: 251/100000
epoch: 251 mean_rewards: [310.66] mean_lengths: 295.62372
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 252
fps step: 1457 fps step and policy inference: 1398 fps total: 1386 epoch: 252/100000
epoch: 252 mean_rewards: [310.11] mean_lengths: 295.83813
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 253
fps step: 1457 fps step and policy inference: 1399 fps total: 1388 epoch: 253/100000
epoch: 253 mean_rewards: [309.87] mean_lengths: 295.9617
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.853 c_loss 0.001 b_loss 0.000
a_loss 0.847 c_loss 0.001 b_loss 0.000
a_loss 0.839 c_loss 0.001 b_loss 0.000
a_loss 0.830 c_loss 0.001 b_loss 0.000
a_loss 0.820 c_loss 0.001 b_loss 0.000
a_loss 0.808 c_loss 0.001 b_loss 0.000
epoch num: 254
fps step: 1498 fps step and policy inference: 1426 fps total: 1414 epoch: 254/100000
epoch: 254 mean_rewards: [318.22] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.891 c_loss 0.001 b_loss 0.000
a_loss 0.882 c_loss 0.001 b_loss 0.000
a_loss 0.870 c_loss 0.001 b_loss 0.000
a_loss 0.858 c_loss 0.001 b_loss 0.000
epoch num: 255
fps step: 1482 fps step and policy inference: 1421 fps total: 1409 epoch: 255/100000
epoch: 255 mean_rewards: [318.33] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 256
fps step: 1450 fps step and policy inference: 1390 fps total: 1378 epoch: 256/100000
epoch: 256 mean_rewards: [318.54] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 257
fps step: 1454 fps step and policy inference: 1394 fps total: 1382 epoch: 257/100000
epoch: 257 mean_rewards: [318.28] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.850 c_loss 0.001 b_loss 0.000
a_loss 0.844 c_loss 0.001 b_loss 0.000
a_loss 0.835 c_loss 0.001 b_loss 0.000
a_loss 0.828 c_loss 0.001 b_loss 0.000
a_loss 0.819 c_loss 0.001 b_loss 0.000
a_loss 0.807 c_loss 0.001 b_loss 0.000
epoch num: 258
fps step: 1449 fps step and policy inference: 1381 fps total: 1369 epoch: 258/100000
epoch: 258 mean_rewards: [315.32] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.001 b_loss 0.000
a_loss 0.900 c_loss 0.001 b_loss 0.000
a_loss 0.891 c_loss 0.001 b_loss 0.000
a_loss 0.882 c_loss 0.001 b_loss 0.000
a_loss 0.871 c_loss 0.001 b_loss 0.000
a_loss 0.858 c_loss 0.001 b_loss 0.000
epoch num: 259
fps step: 1476 fps step and policy inference: 1419 fps total: 1406 epoch: 259/100000
epoch: 259 mean_rewards: [314.95] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 260
fps step: 1497 fps step and policy inference: 1435 fps total: 1423 epoch: 260/100000
epoch: 260 mean_rewards: [315.69] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 261
fps step: 1485 fps step and policy inference: 1420 fps total: 1409 epoch: 261/100000
epoch: 261 mean_rewards: [316.22] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.001 b_loss 0.000
a_loss 0.900 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.870 c_loss 0.001 b_loss 0.000
a_loss 0.858 c_loss 0.001 b_loss 0.000
epoch num: 262
fps step: 1478 fps step and policy inference: 1417 fps total: 1406 epoch: 262/100000
epoch: 262 mean_rewards: [316.96] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.863 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
a_loss 0.849 c_loss 0.001 b_loss 0.000
a_loss 0.840 c_loss 0.001 b_loss 0.000
a_loss 0.830 c_loss 0.001 b_loss 0.000
a_loss 0.818 c_loss 0.001 b_loss 0.000
epoch num: 263
fps step: 1488 fps step and policy inference: 1415 fps total: 1403 epoch: 263/100000
epoch: 263 mean_rewards: [320.61] mean_lengths: 297.39694
saving next best rewards:  [320.61]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.891 c_loss 0.001 b_loss 0.000
a_loss 0.882 c_loss 0.001 b_loss 0.000
a_loss 0.871 c_loss 0.001 b_loss 0.000
a_loss 0.858 c_loss 0.001 b_loss 0.000
epoch num: 264
fps step: 1508 fps step and policy inference: 1447 fps total: 1434 epoch: 264/100000
epoch: 264 mean_rewards: [320.51] mean_lengths: 297.44873
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.900 c_loss 0.001 b_loss 0.000
a_loss 0.891 c_loss 0.001 b_loss 0.000
a_loss 0.882 c_loss 0.001 b_loss 0.000
a_loss 0.870 c_loss 0.001 b_loss 0.000
a_loss 0.858 c_loss 0.001 b_loss 0.000
epoch num: 265
fps step: 1472 fps step and policy inference: 1410 fps total: 1398 epoch: 265/100000
epoch: 265 mean_rewards: [321.7] mean_lengths: 297.57373
saving next best rewards:  [321.7]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 266
fps step: 1436 fps step and policy inference: 1377 fps total: 1366 epoch: 266/100000
epoch: 266 mean_rewards: [321.78] mean_lengths: 297.6693
saving next best rewards:  [321.78]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 267
fps step: 1439 fps step and policy inference: 1381 fps total: 1370 epoch: 267/100000
epoch: 267 mean_rewards: [321.76] mean_lengths: 297.7611
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.849 c_loss 0.001 b_loss 0.000
a_loss 0.844 c_loss 0.001 b_loss 0.000
a_loss 0.836 c_loss 0.001 b_loss 0.000
a_loss 0.827 c_loss 0.001 b_loss 0.000
a_loss 0.817 c_loss 0.001 b_loss 0.000
a_loss 0.806 c_loss 0.001 b_loss 0.000
epoch num: 268
fps step: 1493 fps step and policy inference: 1422 fps total: 1409 epoch: 268/100000
epoch: 268 mean_rewards: [317.59] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.900 c_loss 0.001 b_loss 0.000
a_loss 0.891 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.870 c_loss 0.001 b_loss 0.000
a_loss 0.858 c_loss 0.001 b_loss 0.000
epoch num: 269
fps step: 1476 fps step and policy inference: 1415 fps total: 1404 epoch: 269/100000
epoch: 269 mean_rewards: [316.63] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.897 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 270
fps step: 1430 fps step and policy inference: 1370 fps total: 1359 epoch: 270/100000
epoch: 270 mean_rewards: [316.57] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 271
fps step: 1462 fps step and policy inference: 1402 fps total: 1391 epoch: 271/100000
epoch: 271 mean_rewards: [316.35] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.858 c_loss 0.001 b_loss 0.000
a_loss 0.853 c_loss 0.001 b_loss 0.000
a_loss 0.846 c_loss 0.001 b_loss 0.000
a_loss 0.839 c_loss 0.001 b_loss 0.000
a_loss 0.828 c_loss 0.001 b_loss 0.000
a_loss 0.816 c_loss 0.001 b_loss 0.000
epoch num: 272
fps step: 1465 fps step and policy inference: 1398 fps total: 1386 epoch: 272/100000
epoch: 272 mean_rewards: [321.09] mean_lengths: 297.15692
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.891 c_loss 0.001 b_loss 0.000
a_loss 0.882 c_loss 0.001 b_loss 0.000
a_loss 0.871 c_loss 0.001 b_loss 0.000
a_loss 0.859 c_loss 0.001 b_loss 0.000
epoch num: 273
fps step: 1507 fps step and policy inference: 1444 fps total: 1432 epoch: 273/100000
epoch: 273 mean_rewards: [313.54] mean_lengths: 291.63293
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.882 c_loss 0.001 b_loss 0.000
a_loss 0.871 c_loss 0.001 b_loss 0.000
a_loss 0.858 c_loss 0.001 b_loss 0.000
epoch num: 274
fps step: 1477 fps step and policy inference: 1416 fps total: 1404 epoch: 274/100000
epoch: 274 mean_rewards: [312.72] mean_lengths: 291.9626
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.854 c_loss 0.001 b_loss 0.000
epoch num: 275
fps step: 1481 fps step and policy inference: 1417 fps total: 1404 epoch: 275/100000
epoch: 275 mean_rewards: [313.28] mean_lengths: 292.50854
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.001 b_loss 0.000
a_loss 0.900 c_loss 0.001 b_loss 0.000
a_loss 0.892 c_loss 0.001 b_loss 0.000
a_loss 0.883 c_loss 0.001 b_loss 0.000
a_loss 0.871 c_loss 0.001 b_loss 0.000
a_loss 0.859 c_loss 0.001 b_loss 0.000
epoch num: 276
fps step: 1471 fps step and policy inference: 1411 fps total: 1400 epoch: 276/100000
epoch: 276 mean_rewards: [312.99] mean_lengths: 292.73105
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.862 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
a_loss 0.849 c_loss 0.001 b_loss 0.000
a_loss 0.841 c_loss 0.001 b_loss 0.000
a_loss 0.829 c_loss 0.001 b_loss 0.000
a_loss 0.818 c_loss 0.001 b_loss 0.000
epoch num: 277
fps step: 1508 fps step and policy inference: 1436 fps total: 1423 epoch: 277/100000
epoch: 277 mean_rewards: [321.22] mean_lengths: 297.36484
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 278
fps step: 1484 fps step and policy inference: 1424 fps total: 1412 epoch: 278/100000
epoch: 278 mean_rewards: [320.97] mean_lengths: 297.41727
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.891 c_loss 0.001 b_loss 0.000
a_loss 0.882 c_loss 0.001 b_loss 0.000
a_loss 0.871 c_loss 0.001 b_loss 0.000
a_loss 0.858 c_loss 0.001 b_loss 0.000
epoch num: 279
fps step: 1452 fps step and policy inference: 1392 fps total: 1380 epoch: 279/100000
epoch: 279 mean_rewards: [322.96] mean_lengths: 297.519
saving next best rewards:  [322.96]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.891 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 280
fps step: 1434 fps step and policy inference: 1376 fps total: 1364 epoch: 280/100000
epoch: 280 mean_rewards: [322.07] mean_lengths: 297.6406
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.896 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 281
fps step: 1437 fps step and policy inference: 1379 fps total: 1368 epoch: 281/100000
epoch: 281 mean_rewards: [321.54] mean_lengths: 297.73355
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.852 c_loss 0.001 b_loss 0.000
a_loss 0.847 c_loss 0.001 b_loss 0.000
a_loss 0.839 c_loss 0.001 b_loss 0.000
a_loss 0.831 c_loss 0.001 b_loss 0.000
a_loss 0.820 c_loss 0.001 b_loss 0.000
a_loss 0.809 c_loss 0.001 b_loss 0.000
epoch num: 282
fps step: 1494 fps step and policy inference: 1424 fps total: 1412 epoch: 282/100000
epoch: 282 mean_rewards: [322.17] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 283
fps step: 1445 fps step and policy inference: 1387 fps total: 1375 epoch: 283/100000
epoch: 283 mean_rewards: [323.11] mean_lengths: 300.0
saving next best rewards:  [323.11]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.870 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 284
fps step: 1424 fps step and policy inference: 1365 fps total: 1354 epoch: 284/100000
epoch: 284 mean_rewards: [323.45] mean_lengths: 300.0
saving next best rewards:  [323.45]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.891 c_loss 0.001 b_loss 0.000
a_loss 0.882 c_loss 0.001 b_loss 0.000
a_loss 0.871 c_loss 0.001 b_loss 0.000
a_loss 0.858 c_loss 0.001 b_loss 0.000
epoch num: 285
fps step: 1466 fps step and policy inference: 1406 fps total: 1394 epoch: 285/100000
epoch: 285 mean_rewards: [323.06] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.874 c_loss 0.001 b_loss 0.000
a_loss 0.866 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
a_loss 0.845 c_loss 0.001 b_loss 0.000
a_loss 0.833 c_loss 0.001 b_loss 0.000
epoch num: 286
fps step: 1488 fps step and policy inference: 1424 fps total: 1411 epoch: 286/100000
epoch: 286 mean_rewards: [325.71] mean_lengths: 300.0
saving next best rewards:  [325.71]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 287
fps step: 1488 fps step and policy inference: 1424 fps total: 1411 epoch: 287/100000
epoch: 287 mean_rewards: [317.48] mean_lengths: 294.7651
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.870 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 288
fps step: 1462 fps step and policy inference: 1402 fps total: 1391 epoch: 288/100000
epoch: 288 mean_rewards: [317.08] mean_lengths: 294.97134
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 289
fps step: 1466 fps step and policy inference: 1402 fps total: 1390 epoch: 289/100000
epoch: 289 mean_rewards: [317.43] mean_lengths: 295.3129
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.880 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 290
fps step: 1478 fps step and policy inference: 1417 fps total: 1405 epoch: 290/100000
epoch: 290 mean_rewards: [316.96] mean_lengths: 295.4521
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.857 c_loss 0.001 b_loss 0.000
a_loss 0.851 c_loss 0.001 b_loss 0.000
a_loss 0.842 c_loss 0.001 b_loss 0.000
a_loss 0.833 c_loss 0.001 b_loss 0.000
a_loss 0.822 c_loss 0.001 b_loss 0.000
a_loss 0.811 c_loss 0.001 b_loss 0.000
epoch num: 291
fps step: 1497 fps step and policy inference: 1426 fps total: 1414 epoch: 291/100000
epoch: 291 mean_rewards: [319.56] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.907 c_loss 0.001 b_loss 0.000
a_loss 0.900 c_loss 0.001 b_loss 0.000
a_loss 0.891 c_loss 0.001 b_loss 0.000
a_loss 0.882 c_loss 0.001 b_loss 0.000
a_loss 0.871 c_loss 0.001 b_loss 0.000
a_loss 0.859 c_loss 0.001 b_loss 0.000
epoch num: 292
fps step: 1469 fps step and policy inference: 1411 fps total: 1399 epoch: 292/100000
epoch: 292 mean_rewards: [319.92] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.879 c_loss 0.001 b_loss 0.000
a_loss 0.868 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
epoch num: 293
fps step: 1401 fps step and policy inference: 1346 fps total: 1336 epoch: 293/100000
epoch: 293 mean_rewards: [320.54] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.889 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.870 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 294
fps step: 1435 fps step and policy inference: 1375 fps total: 1363 epoch: 294/100000
epoch: 294 mean_rewards: [319.97] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.891 c_loss 0.001 b_loss 0.000
a_loss 0.882 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 295
fps step: 1485 fps step and policy inference: 1424 fps total: 1412 epoch: 295/100000
epoch: 295 mean_rewards: [320.11] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.857 c_loss 0.001 b_loss 0.000
a_loss 0.851 c_loss 0.001 b_loss 0.000
a_loss 0.844 c_loss 0.001 b_loss 0.000
a_loss 0.835 c_loss 0.001 b_loss 0.000
a_loss 0.824 c_loss 0.001 b_loss 0.000
a_loss 0.813 c_loss 0.001 b_loss 0.000
epoch num: 296
fps step: 1511 fps step and policy inference: 1438 fps total: 1426 epoch: 296/100000
epoch: 296 mean_rewards: [326.59] mean_lengths: 300.0
saving next best rewards:  [326.59]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 297
fps step: 1477 fps step and policy inference: 1417 fps total: 1406 epoch: 297/100000
epoch: 297 mean_rewards: [327.54] mean_lengths: 300.0
saving next best rewards:  [327.54]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.870 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
epoch num: 298
fps step: 1478 fps step and policy inference: 1415 fps total: 1403 epoch: 298/100000
epoch: 298 mean_rewards: [323.27] mean_lengths: 297.03
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 299
fps step: 1505 fps step and policy inference: 1442 fps total: 1430 epoch: 299/100000
epoch: 299 mean_rewards: [320.37] mean_lengths: 294.24582
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.882 c_loss 0.001 b_loss 0.000
a_loss 0.870 c_loss 0.001 b_loss 0.000
a_loss 0.858 c_loss 0.001 b_loss 0.000
epoch num: 300
fps step: 1500 fps step and policy inference: 1438 fps total: 1426 epoch: 300/100000
epoch: 300 mean_rewards: [320.82] mean_lengths: 294.41672
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/last_Humanoid_ep_300_rew_320.8194.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.892 c_loss 0.001 b_loss 0.000
a_loss 0.885 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.870 c_loss 0.001 b_loss 0.000
a_loss 0.858 c_loss 0.001 b_loss 0.000
a_loss 0.845 c_loss 0.001 b_loss 0.000
epoch num: 301
fps step: 1519 fps step and policy inference: 1446 fps total: 1434 epoch: 301/100000
epoch: 301 mean_rewards: [323.74] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.897 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.855 c_loss 0.000 b_loss 0.000
epoch num: 302
fps step: 1498 fps step and policy inference: 1435 fps total: 1423 epoch: 302/100000
epoch: 302 mean_rewards: [323.62] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 303
fps step: 1469 fps step and policy inference: 1408 fps total: 1397 epoch: 303/100000
epoch: 303 mean_rewards: [323.04] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.890 c_loss 0.001 b_loss 0.000
a_loss 0.881 c_loss 0.001 b_loss 0.000
a_loss 0.869 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 304
fps step: 1447 fps step and policy inference: 1386 fps total: 1374 epoch: 304/100000
epoch: 304 mean_rewards: [322.74] mean_lengths: 299.49
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.851 c_loss 0.001 b_loss 0.000
a_loss 0.846 c_loss 0.001 b_loss 0.000
a_loss 0.839 c_loss 0.001 b_loss 0.000
a_loss 0.831 c_loss 0.001 b_loss 0.000
a_loss 0.819 c_loss 0.001 b_loss 0.000
a_loss 0.807 c_loss 0.001 b_loss 0.000
epoch num: 305
fps step: 1471 fps step and policy inference: 1400 fps total: 1388 epoch: 305/100000
epoch: 305 mean_rewards: [316.82] mean_lengths: 297.40875
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 306
fps step: 1482 fps step and policy inference: 1424 fps total: 1412 epoch: 306/100000
epoch: 306 mean_rewards: [316.82] mean_lengths: 297.40875
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.001 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 307
fps step: 1444 fps step and policy inference: 1382 fps total: 1371 epoch: 307/100000
epoch: 307 mean_rewards: [314.84] mean_lengths: 294.67886
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.001 b_loss 0.000
a_loss 0.898 c_loss 0.001 b_loss 0.000
a_loss 0.888 c_loss 0.001 b_loss 0.000
a_loss 0.878 c_loss 0.001 b_loss 0.000
a_loss 0.867 c_loss 0.001 b_loss 0.000
a_loss 0.856 c_loss 0.001 b_loss 0.000
epoch num: 308
fps step: 1452 fps step and policy inference: 1389 fps total: 1377 epoch: 308/100000
epoch: 308 mean_rewards: [312.51] mean_lengths: 293.7498
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 309
fps step: 1441 fps step and policy inference: 1383 fps total: 1371 epoch: 309/100000
epoch: 309 mean_rewards: [312.22] mean_lengths: 293.99603
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.860 c_loss 0.001 b_loss 0.000
a_loss 0.855 c_loss 0.001 b_loss 0.000
a_loss 0.848 c_loss 0.001 b_loss 0.000
a_loss 0.839 c_loss 0.001 b_loss 0.000
a_loss 0.829 c_loss 0.001 b_loss 0.000
a_loss 0.817 c_loss 0.001 b_loss 0.000
epoch num: 310
fps step: 1471 fps step and policy inference: 1401 fps total: 1390 epoch: 310/100000
epoch: 310 mean_rewards: [317.49] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 311
fps step: 1482 fps step and policy inference: 1423 fps total: 1410 epoch: 311/100000
epoch: 311 mean_rewards: [316.82] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 312
fps step: 1466 fps step and policy inference: 1403 fps total: 1391 epoch: 312/100000
epoch: 312 mean_rewards: [312.49] mean_lengths: 295.82135
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 313
fps step: 1496 fps step and policy inference: 1432 fps total: 1420 epoch: 313/100000
epoch: 313 mean_rewards: [308.57] mean_lengths: 293.15396
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.897 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.855 c_loss 0.000 b_loss 0.000
epoch num: 314
fps step: 1497 fps step and policy inference: 1435 fps total: 1422 epoch: 314/100000
epoch: 314 mean_rewards: [310.24] mean_lengths: 293.42368
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.863 c_loss 0.001 b_loss 0.000
a_loss 0.859 c_loss 0.001 b_loss 0.000
a_loss 0.851 c_loss 0.001 b_loss 0.000
a_loss 0.843 c_loss 0.001 b_loss 0.000
a_loss 0.832 c_loss 0.001 b_loss 0.000
a_loss 0.820 c_loss 0.001 b_loss 0.000
epoch num: 315
fps step: 1486 fps step and policy inference: 1417 fps total: 1405 epoch: 315/100000
epoch: 315 mean_rewards: [321.03] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 316
fps step: 1470 fps step and policy inference: 1409 fps total: 1397 epoch: 316/100000
epoch: 316 mean_rewards: [320.32] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 317
fps step: 1472 fps step and policy inference: 1409 fps total: 1397 epoch: 317/100000
epoch: 317 mean_rewards: [319.72] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 318
fps step: 1436 fps step and policy inference: 1378 fps total: 1366 epoch: 318/100000
epoch: 318 mean_rewards: [319.89] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.850 c_loss 0.001 b_loss 0.000
a_loss 0.845 c_loss 0.001 b_loss 0.000
a_loss 0.837 c_loss 0.001 b_loss 0.000
a_loss 0.829 c_loss 0.001 b_loss 0.000
a_loss 0.818 c_loss 0.001 b_loss 0.000
a_loss 0.806 c_loss 0.001 b_loss 0.000
epoch num: 319
fps step: 1465 fps step and policy inference: 1397 fps total: 1385 epoch: 319/100000
epoch: 319 mean_rewards: [317.68] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 320
fps step: 1432 fps step and policy inference: 1377 fps total: 1366 epoch: 320/100000
epoch: 320 mean_rewards: [317.68] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 321
fps step: 1440 fps step and policy inference: 1381 fps total: 1370 epoch: 321/100000
epoch: 321 mean_rewards: [317.32] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 322
fps step: 1423 fps step and policy inference: 1361 fps total: 1350 epoch: 322/100000
epoch: 322 mean_rewards: [317.68] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.855 c_loss 0.000 b_loss 0.000
epoch num: 323
fps step: 1418 fps step and policy inference: 1362 fps total: 1351 epoch: 323/100000
epoch: 323 mean_rewards: [317.48] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.863 c_loss 0.001 b_loss 0.000
a_loss 0.858 c_loss 0.001 b_loss 0.000
a_loss 0.850 c_loss 0.001 b_loss 0.000
a_loss 0.842 c_loss 0.001 b_loss 0.000
a_loss 0.831 c_loss 0.001 b_loss 0.000
a_loss 0.819 c_loss 0.001 b_loss 0.000
epoch num: 324
fps step: 1503 fps step and policy inference: 1432 fps total: 1420 epoch: 324/100000
epoch: 324 mean_rewards: [324.97] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 325
fps step: 1469 fps step and policy inference: 1410 fps total: 1398 epoch: 325/100000
epoch: 325 mean_rewards: [324.99] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 326
fps step: 1473 fps step and policy inference: 1409 fps total: 1397 epoch: 326/100000
epoch: 326 mean_rewards: [324.23] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 327
fps step: 1440 fps step and policy inference: 1379 fps total: 1368 epoch: 327/100000
epoch: 327 mean_rewards: [323.76] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 328
fps step: 1459 fps step and policy inference: 1399 fps total: 1388 epoch: 328/100000
epoch: 328 mean_rewards: [323.24] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.853 c_loss 0.001 b_loss 0.000
a_loss 0.848 c_loss 0.001 b_loss 0.000
a_loss 0.840 c_loss 0.001 b_loss 0.000
a_loss 0.833 c_loss 0.001 b_loss 0.000
a_loss 0.822 c_loss 0.001 b_loss 0.000
a_loss 0.811 c_loss 0.001 b_loss 0.000
epoch num: 329
fps step: 1517 fps step and policy inference: 1446 fps total: 1433 epoch: 329/100000
epoch: 329 mean_rewards: [321.3] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 330
fps step: 1474 fps step and policy inference: 1413 fps total: 1401 epoch: 330/100000
epoch: 330 mean_rewards: [322.21] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.867 c_loss 0.000 b_loss 0.000
a_loss 0.855 c_loss 0.000 b_loss 0.000
epoch num: 331
fps step: 1482 fps step and policy inference: 1416 fps total: 1404 epoch: 331/100000
epoch: 331 mean_rewards: [321.19] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 332
fps step: 1465 fps step and policy inference: 1405 fps total: 1393 epoch: 332/100000
epoch: 332 mean_rewards: [321.05] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.852 c_loss 0.001 b_loss 0.000
a_loss 0.847 c_loss 0.001 b_loss 0.000
a_loss 0.839 c_loss 0.001 b_loss 0.000
a_loss 0.832 c_loss 0.001 b_loss 0.000
a_loss 0.821 c_loss 0.001 b_loss 0.000
a_loss 0.809 c_loss 0.001 b_loss 0.000
epoch num: 333
fps step: 1465 fps step and policy inference: 1394 fps total: 1383 epoch: 333/100000
epoch: 333 mean_rewards: [318.77] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.907 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 334
fps step: 1490 fps step and policy inference: 1432 fps total: 1419 epoch: 334/100000
epoch: 334 mean_rewards: [319.5] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.897 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.867 c_loss 0.000 b_loss 0.000
a_loss 0.854 c_loss 0.000 b_loss 0.000
epoch num: 335
fps step: 1479 fps step and policy inference: 1417 fps total: 1406 epoch: 335/100000
epoch: 335 mean_rewards: [318.39] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 336
fps step: 1493 fps step and policy inference: 1424 fps total: 1412 epoch: 336/100000
epoch: 336 mean_rewards: [319.05] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 337
fps step: 1471 fps step and policy inference: 1409 fps total: 1397 epoch: 337/100000
epoch: 337 mean_rewards: [318.48] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.865 c_loss 0.001 b_loss 0.000
a_loss 0.859 c_loss 0.001 b_loss 0.000
a_loss 0.852 c_loss 0.001 b_loss 0.000
a_loss 0.844 c_loss 0.001 b_loss 0.000
a_loss 0.834 c_loss 0.001 b_loss 0.000
a_loss 0.822 c_loss 0.001 b_loss 0.000
epoch num: 338
fps step: 1497 fps step and policy inference: 1426 fps total: 1414 epoch: 338/100000
epoch: 338 mean_rewards: [319.04] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 339
fps step: 1458 fps step and policy inference: 1401 fps total: 1389 epoch: 339/100000
epoch: 339 mean_rewards: [319.25] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 340
fps step: 1485 fps step and policy inference: 1421 fps total: 1409 epoch: 340/100000
epoch: 340 mean_rewards: [321.17] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.896 c_loss 0.000 b_loss 0.000
a_loss 0.887 c_loss 0.000 b_loss 0.000
a_loss 0.879 c_loss 0.000 b_loss 0.000
a_loss 0.867 c_loss 0.000 b_loss 0.000
a_loss 0.853 c_loss 0.000 b_loss 0.000
epoch num: 341
fps step: 1463 fps step and policy inference: 1402 fps total: 1391 epoch: 341/100000
epoch: 341 mean_rewards: [320.27] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 342
fps step: 1490 fps step and policy inference: 1427 fps total: 1415 epoch: 342/100000
epoch: 342 mean_rewards: [319.61] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.850 c_loss 0.001 b_loss 0.000
a_loss 0.844 c_loss 0.001 b_loss 0.000
a_loss 0.837 c_loss 0.001 b_loss 0.000
a_loss 0.829 c_loss 0.001 b_loss 0.000
a_loss 0.818 c_loss 0.001 b_loss 0.000
a_loss 0.806 c_loss 0.001 b_loss 0.000
epoch num: 343
fps step: 1484 fps step and policy inference: 1415 fps total: 1404 epoch: 343/100000
epoch: 343 mean_rewards: [312.55] mean_lengths: 297.40875
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 344
fps step: 1467 fps step and policy inference: 1406 fps total: 1394 epoch: 344/100000
epoch: 344 mean_rewards: [310.72] mean_lengths: 295.46155
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.897 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 345
fps step: 1462 fps step and policy inference: 1398 fps total: 1386 epoch: 345/100000
epoch: 345 mean_rewards: [310.68] mean_lengths: 295.8121
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 346
fps step: 1453 fps step and policy inference: 1394 fps total: 1382 epoch: 346/100000
epoch: 346 mean_rewards: [312.75] mean_lengths: 295.97708
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.860 c_loss 0.000 b_loss 0.000
a_loss 0.855 c_loss 0.000 b_loss 0.000
a_loss 0.847 c_loss 0.000 b_loss 0.000
a_loss 0.838 c_loss 0.000 b_loss 0.000
a_loss 0.827 c_loss 0.000 b_loss 0.000
a_loss 0.815 c_loss 0.000 b_loss 0.000
epoch num: 347
fps step: 1489 fps step and policy inference: 1420 fps total: 1408 epoch: 347/100000
epoch: 347 mean_rewards: [315.72] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 348
fps step: 1486 fps step and policy inference: 1425 fps total: 1413 epoch: 348/100000
epoch: 348 mean_rewards: [317.2] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 349
fps step: 1460 fps step and policy inference: 1400 fps total: 1388 epoch: 349/100000
epoch: 349 mean_rewards: [317.12] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.896 c_loss 0.000 b_loss 0.000
a_loss 0.888 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.855 c_loss 0.000 b_loss 0.000
epoch num: 350
fps step: 1490 fps step and policy inference: 1422 fps total: 1410 epoch: 350/100000
epoch: 350 mean_rewards: [316.81] mean_lengths: 300.0
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/last_Humanoid_ep_350_rew_316.80548.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 351
fps step: 1459 fps step and policy inference: 1399 fps total: 1388 epoch: 351/100000
epoch: 351 mean_rewards: [316.81] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.863 c_loss 0.001 b_loss 0.000
a_loss 0.857 c_loss 0.001 b_loss 0.000
a_loss 0.850 c_loss 0.001 b_loss 0.000
a_loss 0.842 c_loss 0.001 b_loss 0.000
a_loss 0.831 c_loss 0.001 b_loss 0.000
a_loss 0.818 c_loss 0.001 b_loss 0.000
epoch num: 352
fps step: 1467 fps step and policy inference: 1399 fps total: 1388 epoch: 352/100000
epoch: 352 mean_rewards: [317.4] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 353
fps step: 1467 fps step and policy inference: 1409 fps total: 1397 epoch: 353/100000
epoch: 353 mean_rewards: [318.47] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 354
fps step: 1465 fps step and policy inference: 1404 fps total: 1392 epoch: 354/100000
epoch: 354 mean_rewards: [319.02] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.879 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.855 c_loss 0.000 b_loss 0.000
epoch num: 355
fps step: 1452 fps step and policy inference: 1390 fps total: 1379 epoch: 355/100000
epoch: 355 mean_rewards: [321.24] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 356
fps step: 1475 fps step and policy inference: 1413 fps total: 1401 epoch: 356/100000
epoch: 356 mean_rewards: [322.41] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.853 c_loss 0.001 b_loss 0.000
a_loss 0.847 c_loss 0.001 b_loss 0.000
a_loss 0.839 c_loss 0.001 b_loss 0.000
a_loss 0.831 c_loss 0.001 b_loss 0.000
a_loss 0.821 c_loss 0.001 b_loss 0.000
a_loss 0.810 c_loss 0.001 b_loss 0.000
epoch num: 357
fps step: 1504 fps step and policy inference: 1433 fps total: 1421 epoch: 357/100000
epoch: 357 mean_rewards: [318.65] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 358
fps step: 1448 fps step and policy inference: 1389 fps total: 1378 epoch: 358/100000
epoch: 358 mean_rewards: [318.4] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.897 c_loss 0.000 b_loss 0.000
a_loss 0.888 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 359
fps step: 1421 fps step and policy inference: 1360 fps total: 1348 epoch: 359/100000
epoch: 359 mean_rewards: [319.24] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 360
fps step: 1467 fps step and policy inference: 1407 fps total: 1395 epoch: 360/100000
epoch: 360 mean_rewards: [319.08] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.875 c_loss 0.000 b_loss 0.000
a_loss 0.867 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
a_loss 0.847 c_loss 0.000 b_loss 0.000
a_loss 0.835 c_loss 0.000 b_loss 0.000
epoch num: 361
fps step: 1498 fps step and policy inference: 1431 fps total: 1418 epoch: 361/100000
epoch: 361 mean_rewards: [324.63] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.878 c_loss 0.000 b_loss 0.000
a_loss 0.867 c_loss 0.000 b_loss 0.000
a_loss 0.855 c_loss 0.000 b_loss 0.000
epoch num: 362
fps step: 1455 fps step and policy inference: 1393 fps total: 1382 epoch: 362/100000
epoch: 362 mean_rewards: [324.17] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 363
fps step: 1446 fps step and policy inference: 1386 fps total: 1374 epoch: 363/100000
epoch: 363 mean_rewards: [324.93] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 364
fps step: 1454 fps step and policy inference: 1390 fps total: 1379 epoch: 364/100000
epoch: 364 mean_rewards: [325.05] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 365
fps step: 1485 fps step and policy inference: 1423 fps total: 1411 epoch: 365/100000
epoch: 365 mean_rewards: [325.75] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.858 c_loss 0.001 b_loss 0.000
a_loss 0.852 c_loss 0.001 b_loss 0.000
a_loss 0.844 c_loss 0.001 b_loss 0.000
a_loss 0.835 c_loss 0.001 b_loss 0.000
a_loss 0.824 c_loss 0.001 b_loss 0.000
a_loss 0.814 c_loss 0.001 b_loss 0.000
epoch num: 366
fps step: 1487 fps step and policy inference: 1417 fps total: 1406 epoch: 366/100000
epoch: 366 mean_rewards: [325.58] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.907 c_loss 0.000 b_loss 0.000
a_loss 0.902 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 367
fps step: 1464 fps step and policy inference: 1406 fps total: 1394 epoch: 367/100000
epoch: 367 mean_rewards: [325.57] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 368
fps step: 1453 fps step and policy inference: 1394 fps total: 1382 epoch: 368/100000
epoch: 368 mean_rewards: [324.79] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 369
fps step: 1454 fps step and policy inference: 1391 fps total: 1379 epoch: 369/100000
epoch: 369 mean_rewards: [325.99] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 370
fps step: 1478 fps step and policy inference: 1417 fps total: 1405 epoch: 370/100000
epoch: 370 mean_rewards: [325.84] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.856 c_loss 0.000 b_loss 0.000
a_loss 0.851 c_loss 0.000 b_loss 0.000
a_loss 0.844 c_loss 0.000 b_loss 0.000
a_loss 0.836 c_loss 0.000 b_loss 0.000
a_loss 0.824 c_loss 0.000 b_loss 0.000
a_loss 0.813 c_loss 0.000 b_loss 0.000
epoch num: 371
fps step: 1482 fps step and policy inference: 1412 fps total: 1400 epoch: 371/100000
epoch: 371 mean_rewards: [325.83] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 372
fps step: 1470 fps step and policy inference: 1408 fps total: 1396 epoch: 372/100000
epoch: 372 mean_rewards: [326.28] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 373
fps step: 1479 fps step and policy inference: 1415 fps total: 1403 epoch: 373/100000
epoch: 373 mean_rewards: [324.88] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 374
fps step: 1489 fps step and policy inference: 1426 fps total: 1414 epoch: 374/100000
epoch: 374 mean_rewards: [324.32] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 375
fps step: 1490 fps step and policy inference: 1428 fps total: 1416 epoch: 375/100000
epoch: 375 mean_rewards: [325.12] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.885 c_loss 0.000 b_loss 0.000
a_loss 0.877 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
a_loss 0.844 c_loss 0.000 b_loss 0.000
epoch num: 376
fps step: 1479 fps step and policy inference: 1410 fps total: 1398 epoch: 376/100000
epoch: 376 mean_rewards: [315.8] mean_lengths: 297.3473
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.897 c_loss 0.000 b_loss 0.000
a_loss 0.888 c_loss 0.000 b_loss 0.000
a_loss 0.879 c_loss 0.000 b_loss 0.000
a_loss 0.867 c_loss 0.000 b_loss 0.000
a_loss 0.854 c_loss 0.000 b_loss 0.000
epoch num: 377
fps step: 1475 fps step and policy inference: 1413 fps total: 1401 epoch: 377/100000
epoch: 377 mean_rewards: [313.82] mean_lengths: 295.4443
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.897 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 378
fps step: 1503 fps step and policy inference: 1437 fps total: 1424 epoch: 378/100000
epoch: 378 mean_rewards: [313.58] mean_lengths: 295.75372
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.867 c_loss 0.000 b_loss 0.000
a_loss 0.855 c_loss 0.000 b_loss 0.000
epoch num: 379
fps step: 1482 fps step and policy inference: 1419 fps total: 1407 epoch: 379/100000
epoch: 379 mean_rewards: [313.63] mean_lengths: 295.96176
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.854 c_loss 0.000 b_loss 0.000
a_loss 0.849 c_loss 0.000 b_loss 0.000
a_loss 0.841 c_loss 0.000 b_loss 0.000
a_loss 0.832 c_loss 0.000 b_loss 0.000
a_loss 0.822 c_loss 0.000 b_loss 0.000
a_loss 0.810 c_loss 0.000 b_loss 0.000
epoch num: 380
fps step: 1490 fps step and policy inference: 1419 fps total: 1407 epoch: 380/100000
epoch: 380 mean_rewards: [315.98] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.907 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 381
fps step: 1507 fps step and policy inference: 1448 fps total: 1436 epoch: 381/100000
epoch: 381 mean_rewards: [315.98] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 382
fps step: 1473 fps step and policy inference: 1408 fps total: 1397 epoch: 382/100000
epoch: 382 mean_rewards: [317.92] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.879 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.855 c_loss 0.000 b_loss 0.000
epoch num: 383
fps step: 1485 fps step and policy inference: 1419 fps total: 1407 epoch: 383/100000
epoch: 383 mean_rewards: [318.41] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 384
fps step: 1488 fps step and policy inference: 1426 fps total: 1414 epoch: 384/100000
epoch: 384 mean_rewards: [319.16] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.862 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
a_loss 0.848 c_loss 0.000 b_loss 0.000
a_loss 0.840 c_loss 0.000 b_loss 0.000
a_loss 0.829 c_loss 0.000 b_loss 0.000
a_loss 0.818 c_loss 0.000 b_loss 0.000
epoch num: 385
fps step: 1503 fps step and policy inference: 1431 fps total: 1419 epoch: 385/100000
epoch: 385 mean_rewards: [331.46] mean_lengths: 300.0
saving next best rewards:  [331.46]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.879 c_loss 0.000 b_loss 0.000
a_loss 0.867 c_loss 0.000 b_loss 0.000
a_loss 0.855 c_loss 0.000 b_loss 0.000
epoch num: 386
fps step: 1495 fps step and policy inference: 1432 fps total: 1420 epoch: 386/100000
epoch: 386 mean_rewards: [329.84] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 387
fps step: 1497 fps step and policy inference: 1430 fps total: 1418 epoch: 387/100000
epoch: 387 mean_rewards: [330.53] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 388
fps step: 1504 fps step and policy inference: 1439 fps total: 1426 epoch: 388/100000
epoch: 388 mean_rewards: [329.96] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 389
fps step: 1492 fps step and policy inference: 1430 fps total: 1418 epoch: 389/100000
epoch: 389 mean_rewards: [328.78] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.866 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
a_loss 0.852 c_loss 0.000 b_loss 0.000
a_loss 0.843 c_loss 0.000 b_loss 0.000
a_loss 0.833 c_loss 0.000 b_loss 0.000
a_loss 0.821 c_loss 0.000 b_loss 0.000
epoch num: 390
fps step: 1488 fps step and policy inference: 1418 fps total: 1406 epoch: 390/100000
epoch: 390 mean_rewards: [327.33] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 391
fps step: 1462 fps step and policy inference: 1400 fps total: 1389 epoch: 391/100000
epoch: 391 mean_rewards: [326.78] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.867 c_loss 0.000 b_loss 0.000
a_loss 0.854 c_loss 0.000 b_loss 0.000
epoch num: 392
fps step: 1468 fps step and policy inference: 1404 fps total: 1392 epoch: 392/100000
epoch: 392 mean_rewards: [326.05] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 393
fps step: 1448 fps step and policy inference: 1387 fps total: 1376 epoch: 393/100000
epoch: 393 mean_rewards: [325.3] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.851 c_loss 0.001 b_loss 0.000
a_loss 0.845 c_loss 0.001 b_loss 0.000
a_loss 0.837 c_loss 0.001 b_loss 0.000
a_loss 0.829 c_loss 0.001 b_loss 0.000
a_loss 0.819 c_loss 0.000 b_loss 0.000
a_loss 0.807 c_loss 0.000 b_loss 0.000
epoch num: 394
fps step: 1481 fps step and policy inference: 1411 fps total: 1400 epoch: 394/100000
epoch: 394 mean_rewards: [320.09] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 395
fps step: 1466 fps step and policy inference: 1410 fps total: 1398 epoch: 395/100000
epoch: 395 mean_rewards: [320.09] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 396
fps step: 1468 fps step and policy inference: 1406 fps total: 1394 epoch: 396/100000
epoch: 396 mean_rewards: [320.08] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.897 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 397
fps step: 1497 fps step and policy inference: 1429 fps total: 1417 epoch: 397/100000
epoch: 397 mean_rewards: [318.29] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 398
fps step: 1499 fps step and policy inference: 1435 fps total: 1424 epoch: 398/100000
epoch: 398 mean_rewards: [319.38] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.865 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
a_loss 0.852 c_loss 0.000 b_loss 0.000
a_loss 0.844 c_loss 0.000 b_loss 0.000
a_loss 0.833 c_loss 0.000 b_loss 0.000
a_loss 0.821 c_loss 0.000 b_loss 0.000
epoch num: 399
fps step: 1469 fps step and policy inference: 1401 fps total: 1390 epoch: 399/100000
epoch: 399 mean_rewards: [332.24] mean_lengths: 300.0
saving next best rewards:  [332.24]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 400
fps step: 1521 fps step and policy inference: 1457 fps total: 1445 epoch: 400/100000
epoch: 400 mean_rewards: [331.45] mean_lengths: 300.0
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/last_Humanoid_ep_400_rew_331.45374.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 401
fps step: 1489 fps step and policy inference: 1425 fps total: 1412 epoch: 401/100000
epoch: 401 mean_rewards: [330.21] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 402
fps step: 1513 fps step and policy inference: 1446 fps total: 1433 epoch: 402/100000
epoch: 402 mean_rewards: [328.46] mean_lengths: 297.31
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.907 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 403
fps step: 1526 fps step and policy inference: 1461 fps total: 1448 epoch: 403/100000
epoch: 403 mean_rewards: [327.7] mean_lengths: 297.41595
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.852 c_loss 0.000 b_loss 0.000
a_loss 0.846 c_loss 0.000 b_loss 0.000
a_loss 0.838 c_loss 0.000 b_loss 0.000
a_loss 0.830 c_loss 0.000 b_loss 0.000
a_loss 0.820 c_loss 0.000 b_loss 0.000
a_loss 0.808 c_loss 0.000 b_loss 0.000
epoch num: 404
fps step: 1512 fps step and policy inference: 1442 fps total: 1429 epoch: 404/100000
epoch: 404 mean_rewards: [320.67] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 405
fps step: 1502 fps step and policy inference: 1438 fps total: 1425 epoch: 405/100000
epoch: 405 mean_rewards: [321.06] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 406
fps step: 1481 fps step and policy inference: 1417 fps total: 1405 epoch: 406/100000
epoch: 406 mean_rewards: [321.15] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 407
fps step: 1482 fps step and policy inference: 1422 fps total: 1409 epoch: 407/100000
epoch: 407 mean_rewards: [321.2] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.852 c_loss 0.000 b_loss 0.000
a_loss 0.848 c_loss 0.000 b_loss 0.000
a_loss 0.840 c_loss 0.000 b_loss 0.000
a_loss 0.832 c_loss 0.000 b_loss 0.000
a_loss 0.820 c_loss 0.000 b_loss 0.000
a_loss 0.809 c_loss 0.000 b_loss 0.000
epoch num: 408
fps step: 1485 fps step and policy inference: 1414 fps total: 1402 epoch: 408/100000
epoch: 408 mean_rewards: [316.81] mean_lengths: 297.11
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.907 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 409
fps step: 1500 fps step and policy inference: 1440 fps total: 1427 epoch: 409/100000
epoch: 409 mean_rewards: [314.07] mean_lengths: 294.20667
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 410
fps step: 1482 fps step and policy inference: 1419 fps total: 1407 epoch: 410/100000
epoch: 410 mean_rewards: [316.27] mean_lengths: 294.54565
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.897 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 411
fps step: 1487 fps step and policy inference: 1420 fps total: 1408 epoch: 411/100000
epoch: 411 mean_rewards: [315.82] mean_lengths: 293.70792
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 412
fps step: 1491 fps step and policy inference: 1427 fps total: 1415 epoch: 412/100000
epoch: 412 mean_rewards: [316.32] mean_lengths: 294.0163
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.862 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
a_loss 0.850 c_loss 0.000 b_loss 0.000
a_loss 0.841 c_loss 0.000 b_loss 0.000
a_loss 0.831 c_loss 0.000 b_loss 0.000
a_loss 0.819 c_loss 0.000 b_loss 0.000
epoch num: 413
fps step: 1478 fps step and policy inference: 1409 fps total: 1396 epoch: 413/100000
epoch: 413 mean_rewards: [324.47] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 414
fps step: 1508 fps step and policy inference: 1444 fps total: 1431 epoch: 414/100000
epoch: 414 mean_rewards: [325.53] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.897 c_loss 0.000 b_loss 0.000
a_loss 0.888 c_loss 0.000 b_loss 0.000
a_loss 0.879 c_loss 0.000 b_loss 0.000
a_loss 0.866 c_loss 0.000 b_loss 0.000
a_loss 0.853 c_loss 0.000 b_loss 0.000
epoch num: 415
fps step: 1480 fps step and policy inference: 1414 fps total: 1401 epoch: 415/100000
epoch: 415 mean_rewards: [323.03] mean_lengths: 298.29013
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 416
fps step: 1447 fps step and policy inference: 1387 fps total: 1376 epoch: 416/100000
epoch: 416 mean_rewards: [324.17] mean_lengths: 298.37408
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 417
fps step: 1460 fps step and policy inference: 1398 fps total: 1386 epoch: 417/100000
epoch: 417 mean_rewards: [322.81] mean_lengths: 298.4692
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.851 c_loss 0.000 b_loss 0.000
a_loss 0.846 c_loss 0.000 b_loss 0.000
a_loss 0.838 c_loss 0.000 b_loss 0.000
a_loss 0.830 c_loss 0.000 b_loss 0.000
a_loss 0.819 c_loss 0.000 b_loss 0.000
a_loss 0.808 c_loss 0.000 b_loss 0.000
epoch num: 418
fps step: 1490 fps step and policy inference: 1420 fps total: 1408 epoch: 418/100000
epoch: 418 mean_rewards: [314.38] mean_lengths: 297.20554
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 419
fps step: 1469 fps step and policy inference: 1407 fps total: 1395 epoch: 419/100000
epoch: 419 mean_rewards: [315.09] mean_lengths: 297.34247
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 420
fps step: 1479 fps step and policy inference: 1412 fps total: 1400 epoch: 420/100000
epoch: 420 mean_rewards: [316.84] mean_lengths: 297.59674
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 421
fps step: 1481 fps step and policy inference: 1419 fps total: 1407 epoch: 421/100000
epoch: 421 mean_rewards: [317.58] mean_lengths: 297.69147
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.860 c_loss 0.000 b_loss 0.000
a_loss 0.855 c_loss 0.000 b_loss 0.000
a_loss 0.847 c_loss 0.000 b_loss 0.000
a_loss 0.838 c_loss 0.000 b_loss 0.000
a_loss 0.827 c_loss 0.000 b_loss 0.000
a_loss 0.815 c_loss 0.000 b_loss 0.000
epoch num: 422
fps step: 1428 fps step and policy inference: 1364 fps total: 1353 epoch: 422/100000
epoch: 422 mean_rewards: [320.43] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 423
fps step: 1493 fps step and policy inference: 1431 fps total: 1419 epoch: 423/100000
epoch: 423 mean_rewards: [318.78] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 424
fps step: 1433 fps step and policy inference: 1372 fps total: 1361 epoch: 424/100000
epoch: 424 mean_rewards: [318.94] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.897 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.855 c_loss 0.000 b_loss 0.000
epoch num: 425
fps step: 1466 fps step and policy inference: 1402 fps total: 1391 epoch: 425/100000
epoch: 425 mean_rewards: [317.93] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 426
fps step: 1450 fps step and policy inference: 1391 fps total: 1379 epoch: 426/100000
epoch: 426 mean_rewards: [317.85] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.862 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
a_loss 0.849 c_loss 0.000 b_loss 0.000
a_loss 0.840 c_loss 0.000 b_loss 0.000
a_loss 0.828 c_loss 0.000 b_loss 0.000
a_loss 0.816 c_loss 0.000 b_loss 0.000
epoch num: 427
fps step: 1460 fps step and policy inference: 1392 fps total: 1380 epoch: 427/100000
epoch: 427 mean_rewards: [323.88] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 428
fps step: 1495 fps step and policy inference: 1434 fps total: 1422 epoch: 428/100000
epoch: 428 mean_rewards: [323.15] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 429
fps step: 1468 fps step and policy inference: 1404 fps total: 1392 epoch: 429/100000
epoch: 429 mean_rewards: [323.68] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 430
fps step: 1462 fps step and policy inference: 1400 fps total: 1388 epoch: 430/100000
epoch: 430 mean_rewards: [322.3] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.879 c_loss 0.000 b_loss 0.000
a_loss 0.867 c_loss 0.000 b_loss 0.000
a_loss 0.855 c_loss 0.000 b_loss 0.000
epoch num: 431
fps step: 1467 fps step and policy inference: 1403 fps total: 1392 epoch: 431/100000
epoch: 431 mean_rewards: [322.97] mean_lengths: 299.5743
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.853 c_loss 0.000 b_loss 0.000
a_loss 0.848 c_loss 0.000 b_loss 0.000
a_loss 0.840 c_loss 0.000 b_loss 0.000
a_loss 0.831 c_loss 0.000 b_loss 0.000
a_loss 0.820 c_loss 0.000 b_loss 0.000
a_loss 0.810 c_loss 0.000 b_loss 0.000
epoch num: 432
fps step: 1444 fps step and policy inference: 1377 fps total: 1365 epoch: 432/100000
epoch: 432 mean_rewards: [322.88] mean_lengths: 297.60385
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 433
fps step: 1449 fps step and policy inference: 1389 fps total: 1377 epoch: 433/100000
epoch: 433 mean_rewards: [324.61] mean_lengths: 297.72125
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 434
fps step: 1439 fps step and policy inference: 1376 fps total: 1365 epoch: 434/100000
epoch: 434 mean_rewards: [324.16] mean_lengths: 297.93933
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 435
fps step: 1488 fps step and policy inference: 1426 fps total: 1414 epoch: 435/100000
epoch: 435 mean_rewards: [324.07] mean_lengths: 298.02048
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.874 c_loss 0.000 b_loss 0.000
a_loss 0.867 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
a_loss 0.847 c_loss 0.000 b_loss 0.000
a_loss 0.834 c_loss 0.000 b_loss 0.000
epoch num: 436
fps step: 1487 fps step and policy inference: 1420 fps total: 1408 epoch: 436/100000
epoch: 436 mean_rewards: [327.23] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.897 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.867 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 437
fps step: 1512 fps step and policy inference: 1443 fps total: 1431 epoch: 437/100000
epoch: 437 mean_rewards: [323.28] mean_lengths: 297.43378
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 438
fps step: 1477 fps step and policy inference: 1413 fps total: 1401 epoch: 438/100000
epoch: 438 mean_rewards: [323.88] mean_lengths: 297.6081
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 439
fps step: 1483 fps step and policy inference: 1417 fps total: 1405 epoch: 439/100000
epoch: 439 mean_rewards: [322.29] mean_lengths: 297.81512
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 440
fps step: 1461 fps step and policy inference: 1398 fps total: 1387 epoch: 440/100000
epoch: 440 mean_rewards: [321.68] mean_lengths: 297.943
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.860 c_loss 0.000 b_loss 0.000
a_loss 0.855 c_loss 0.000 b_loss 0.000
a_loss 0.846 c_loss 0.000 b_loss 0.000
a_loss 0.837 c_loss 0.000 b_loss 0.000
a_loss 0.827 c_loss 0.000 b_loss 0.000
a_loss 0.816 c_loss 0.000 b_loss 0.000
epoch num: 441
fps step: 1498 fps step and policy inference: 1426 fps total: 1414 epoch: 441/100000
epoch: 441 mean_rewards: [328.96] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 442
fps step: 1489 fps step and policy inference: 1429 fps total: 1417 epoch: 442/100000
epoch: 442 mean_rewards: [328.83] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 443
fps step: 1491 fps step and policy inference: 1426 fps total: 1414 epoch: 443/100000
epoch: 443 mean_rewards: [327.9] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 444
fps step: 1487 fps step and policy inference: 1421 fps total: 1409 epoch: 444/100000
epoch: 444 mean_rewards: [326.13] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 445
fps step: 1477 fps step and policy inference: 1414 fps total: 1402 epoch: 445/100000
epoch: 445 mean_rewards: [325.9] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.857 c_loss 0.000 b_loss 0.000
a_loss 0.852 c_loss 0.000 b_loss 0.000
a_loss 0.844 c_loss 0.000 b_loss 0.000
a_loss 0.835 c_loss 0.000 b_loss 0.000
a_loss 0.824 c_loss 0.000 b_loss 0.000
a_loss 0.813 c_loss 0.000 b_loss 0.000
epoch num: 446
fps step: 1499 fps step and policy inference: 1428 fps total: 1415 epoch: 446/100000
epoch: 446 mean_rewards: [325.01] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 447
fps step: 1481 fps step and policy inference: 1419 fps total: 1406 epoch: 447/100000
epoch: 447 mean_rewards: [324.21] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 448
fps step: 1475 fps step and policy inference: 1410 fps total: 1398 epoch: 448/100000
epoch: 448 mean_rewards: [325.75] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 449
fps step: 1477 fps step and policy inference: 1416 fps total: 1404 epoch: 449/100000
epoch: 449 mean_rewards: [328.42] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 450
fps step: 1443 fps step and policy inference: 1383 fps total: 1371 epoch: 450/100000
epoch: 450 mean_rewards: [327.13] mean_lengths: 300.0
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/last_Humanoid_ep_450_rew_327.13077.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.886 c_loss 0.000 b_loss 0.000
a_loss 0.877 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
a_loss 0.845 c_loss 0.000 b_loss 0.000
epoch num: 451
fps step: 1498 fps step and policy inference: 1427 fps total: 1415 epoch: 451/100000
epoch: 451 mean_rewards: [325.95] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 452
fps step: 1488 fps step and policy inference: 1423 fps total: 1411 epoch: 452/100000
epoch: 452 mean_rewards: [326.54] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 453
fps step: 1448 fps step and policy inference: 1385 fps total: 1373 epoch: 453/100000
epoch: 453 mean_rewards: [325.75] mean_lengths: 298.9
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 454
fps step: 1470 fps step and policy inference: 1408 fps total: 1397 epoch: 454/100000
epoch: 454 mean_rewards: [327.98] mean_lengths: 298.9539
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.855 c_loss 0.000 b_loss 0.000
a_loss 0.850 c_loss 0.000 b_loss 0.000
a_loss 0.843 c_loss 0.000 b_loss 0.000
a_loss 0.834 c_loss 0.000 b_loss 0.000
a_loss 0.823 c_loss 0.000 b_loss 0.000
a_loss 0.811 c_loss 0.000 b_loss 0.000
epoch num: 455
fps step: 1490 fps step and policy inference: 1417 fps total: 1405 epoch: 455/100000
epoch: 455 mean_rewards: [326.37] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.907 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.885 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 456
fps step: 1495 fps step and policy inference: 1436 fps total: 1424 epoch: 456/100000
epoch: 456 mean_rewards: [326.37] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 457
fps step: 1501 fps step and policy inference: 1434 fps total: 1422 epoch: 457/100000
epoch: 457 mean_rewards: [325.2] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 458
fps step: 1494 fps step and policy inference: 1428 fps total: 1416 epoch: 458/100000
epoch: 458 mean_rewards: [324.43] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 459
fps step: 1511 fps step and policy inference: 1444 fps total: 1431 epoch: 459/100000
epoch: 459 mean_rewards: [324.13] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.862 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
a_loss 0.848 c_loss 0.000 b_loss 0.000
a_loss 0.841 c_loss 0.000 b_loss 0.000
a_loss 0.830 c_loss 0.000 b_loss 0.000
a_loss 0.818 c_loss 0.000 b_loss 0.000
epoch num: 460
fps step: 1504 fps step and policy inference: 1430 fps total: 1418 epoch: 460/100000
epoch: 460 mean_rewards: [326.48] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 461
fps step: 1477 fps step and policy inference: 1416 fps total: 1404 epoch: 461/100000
epoch: 461 mean_rewards: [326.64] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 462
fps step: 1465 fps step and policy inference: 1401 fps total: 1389 epoch: 462/100000
epoch: 462 mean_rewards: [326.42] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.885 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 463
fps step: 1501 fps step and policy inference: 1437 fps total: 1424 epoch: 463/100000
epoch: 463 mean_rewards: [326.72] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 464
fps step: 1525 fps step and policy inference: 1458 fps total: 1446 epoch: 464/100000
epoch: 464 mean_rewards: [325.37] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.862 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
a_loss 0.850 c_loss 0.000 b_loss 0.000
a_loss 0.843 c_loss 0.000 b_loss 0.000
a_loss 0.832 c_loss 0.000 b_loss 0.000
a_loss 0.821 c_loss 0.000 b_loss 0.000
epoch num: 465
fps step: 1499 fps step and policy inference: 1428 fps total: 1416 epoch: 465/100000
epoch: 465 mean_rewards: [325.08] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 466
fps step: 1477 fps step and policy inference: 1413 fps total: 1401 epoch: 466/100000
epoch: 466 mean_rewards: [326.13] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 467
fps step: 1429 fps step and policy inference: 1368 fps total: 1357 epoch: 467/100000
epoch: 467 mean_rewards: [326.22] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.885 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 468
fps step: 1422 fps step and policy inference: 1363 fps total: 1352 epoch: 468/100000
epoch: 468 mean_rewards: [326.68] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.853 c_loss 0.000 b_loss 0.000
a_loss 0.848 c_loss 0.000 b_loss 0.000
a_loss 0.840 c_loss 0.000 b_loss 0.000
a_loss 0.832 c_loss 0.000 b_loss 0.000
a_loss 0.821 c_loss 0.000 b_loss 0.000
a_loss 0.809 c_loss 0.000 b_loss 0.000
epoch num: 469
fps step: 1449 fps step and policy inference: 1378 fps total: 1367 epoch: 469/100000
epoch: 469 mean_rewards: [326.59] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 470
fps step: 1499 fps step and policy inference: 1439 fps total: 1427 epoch: 470/100000
epoch: 470 mean_rewards: [326.59] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 471
fps step: 1486 fps step and policy inference: 1421 fps total: 1409 epoch: 471/100000
epoch: 471 mean_rewards: [324.65] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 472
fps step: 1470 fps step and policy inference: 1404 fps total: 1392 epoch: 472/100000
epoch: 472 mean_rewards: [325.31] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 473
fps step: 1508 fps step and policy inference: 1441 fps total: 1429 epoch: 473/100000
epoch: 473 mean_rewards: [326.92] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.864 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
a_loss 0.851 c_loss 0.000 b_loss 0.000
a_loss 0.843 c_loss 0.000 b_loss 0.000
a_loss 0.832 c_loss 0.000 b_loss 0.000
a_loss 0.820 c_loss 0.000 b_loss 0.000
epoch num: 474
fps step: 1480 fps step and policy inference: 1408 fps total: 1396 epoch: 474/100000
epoch: 474 mean_rewards: [332.06] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 475
fps step: 1489 fps step and policy inference: 1427 fps total: 1415 epoch: 475/100000
epoch: 475 mean_rewards: [332.49] mean_lengths: 300.0
saving next best rewards:  [332.49]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 476
fps step: 1451 fps step and policy inference: 1388 fps total: 1377 epoch: 476/100000
epoch: 476 mean_rewards: [332.15] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.886 c_loss 0.000 b_loss 0.000
a_loss 0.874 c_loss 0.000 b_loss 0.000
a_loss 0.862 c_loss 0.000 b_loss 0.000
epoch num: 477
fps step: 1475 fps step and policy inference: 1411 fps total: 1400 epoch: 477/100000
epoch: 477 mean_rewards: [332.64] mean_lengths: 300.0
saving next best rewards:  [332.64]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 478
fps step: 1491 fps step and policy inference: 1426 fps total: 1413 epoch: 478/100000
epoch: 478 mean_rewards: [333.13] mean_lengths: 300.0
saving next best rewards:  [333.13]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.855 c_loss 0.000 b_loss 0.000
a_loss 0.850 c_loss 0.000 b_loss 0.000
a_loss 0.843 c_loss 0.000 b_loss 0.000
a_loss 0.836 c_loss 0.000 b_loss 0.000
a_loss 0.826 c_loss 0.000 b_loss 0.000
a_loss 0.814 c_loss 0.000 b_loss 0.000
epoch num: 479
fps step: 1500 fps step and policy inference: 1428 fps total: 1416 epoch: 479/100000
epoch: 479 mean_rewards: [330.19] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 480
fps step: 1482 fps step and policy inference: 1419 fps total: 1407 epoch: 480/100000
epoch: 480 mean_rewards: [330.25] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 481
fps step: 1491 fps step and policy inference: 1423 fps total: 1412 epoch: 481/100000
epoch: 481 mean_rewards: [332.2] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 482
fps step: 1465 fps step and policy inference: 1404 fps total: 1392 epoch: 482/100000
epoch: 482 mean_rewards: [331.01] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.854 c_loss 0.000 b_loss 0.000
a_loss 0.849 c_loss 0.000 b_loss 0.000
a_loss 0.842 c_loss 0.000 b_loss 0.000
a_loss 0.834 c_loss 0.000 b_loss 0.000
a_loss 0.824 c_loss 0.000 b_loss 0.000
a_loss 0.813 c_loss 0.000 b_loss 0.000
epoch num: 483
fps step: 1401 fps step and policy inference: 1334 fps total: 1323 epoch: 483/100000
epoch: 483 mean_rewards: [327.77] mean_lengths: 297.3006
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.907 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.894 c_loss 0.000 b_loss 0.000
a_loss 0.886 c_loss 0.000 b_loss 0.000
a_loss 0.876 c_loss 0.000 b_loss 0.000
a_loss 0.864 c_loss 0.000 b_loss 0.000
epoch num: 484
fps step: 1509 fps step and policy inference: 1447 fps total: 1435 epoch: 484/100000
epoch: 484 mean_rewards: [327.7] mean_lengths: 297.38156
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 485
fps step: 1498 fps step and policy inference: 1431 fps total: 1419 epoch: 485/100000
epoch: 485 mean_rewards: [327.99] mean_lengths: 297.55942
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.874 c_loss 0.000 b_loss 0.000
a_loss 0.863 c_loss 0.000 b_loss 0.000
epoch num: 486
fps step: 1477 fps step and policy inference: 1410 fps total: 1399 epoch: 486/100000
epoch: 486 mean_rewards: [328.46] mean_lengths: 297.79297
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 487
fps step: 1495 fps step and policy inference: 1428 fps total: 1416 epoch: 487/100000
epoch: 487 mean_rewards: [328.23] mean_lengths: 297.94293
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.864 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
a_loss 0.851 c_loss 0.000 b_loss 0.000
a_loss 0.844 c_loss 0.000 b_loss 0.000
a_loss 0.834 c_loss 0.000 b_loss 0.000
a_loss 0.822 c_loss 0.000 b_loss 0.000
epoch num: 488
fps step: 1496 fps step and policy inference: 1424 fps total: 1412 epoch: 488/100000
epoch: 488 mean_rewards: [329.01] mean_lengths: 297.44223
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.907 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.894 c_loss 0.000 b_loss 0.000
a_loss 0.886 c_loss 0.000 b_loss 0.000
a_loss 0.875 c_loss 0.000 b_loss 0.000
a_loss 0.862 c_loss 0.000 b_loss 0.000
epoch num: 489
fps step: 1470 fps step and policy inference: 1411 fps total: 1398 epoch: 489/100000
epoch: 489 mean_rewards: [328.81] mean_lengths: 297.5182
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.894 c_loss 0.000 b_loss 0.000
a_loss 0.886 c_loss 0.000 b_loss 0.000
a_loss 0.874 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 490
fps step: 1483 fps step and policy inference: 1417 fps total: 1406 epoch: 490/100000
epoch: 490 mean_rewards: [329.71] mean_lengths: 297.70987
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 491
fps step: 1492 fps step and policy inference: 1429 fps total: 1416 epoch: 491/100000
epoch: 491 mean_rewards: [328.84] mean_lengths: 297.84402
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 492
fps step: 1485 fps step and policy inference: 1418 fps total: 1406 epoch: 492/100000
epoch: 492 mean_rewards: [328.31] mean_lengths: 298.0105
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.852 c_loss 0.000 b_loss 0.000
a_loss 0.847 c_loss 0.000 b_loss 0.000
a_loss 0.839 c_loss 0.000 b_loss 0.000
a_loss 0.831 c_loss 0.000 b_loss 0.000
a_loss 0.821 c_loss 0.000 b_loss 0.000
a_loss 0.810 c_loss 0.000 b_loss 0.000
epoch num: 493
fps step: 1497 fps step and policy inference: 1424 fps total: 1413 epoch: 493/100000
epoch: 493 mean_rewards: [322.92] mean_lengths: 297.2239
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 494
fps step: 1510 fps step and policy inference: 1445 fps total: 1433 epoch: 494/100000
epoch: 494 mean_rewards: [322.94] mean_lengths: 297.35992
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 495
fps step: 1489 fps step and policy inference: 1421 fps total: 1409 epoch: 495/100000
epoch: 495 mean_rewards: [325.21] mean_lengths: 297.61255
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 496
fps step: 1446 fps step and policy inference: 1384 fps total: 1373 epoch: 496/100000
epoch: 496 mean_rewards: [326.55] mean_lengths: 297.15222
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.863 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
a_loss 0.850 c_loss 0.000 b_loss 0.000
a_loss 0.843 c_loss 0.000 b_loss 0.000
a_loss 0.832 c_loss 0.000 b_loss 0.000
a_loss 0.820 c_loss 0.000 b_loss 0.000
epoch num: 497
fps step: 1475 fps step and policy inference: 1405 fps total: 1393 epoch: 497/100000
epoch: 497 mean_rewards: [328.75] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.862 c_loss 0.000 b_loss 0.000
epoch num: 498
fps step: 1482 fps step and policy inference: 1420 fps total: 1409 epoch: 498/100000
epoch: 498 mean_rewards: [324.62] mean_lengths: 297.1574
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 499
fps step: 1500 fps step and policy inference: 1434 fps total: 1422 epoch: 499/100000
epoch: 499 mean_rewards: [326.07] mean_lengths: 297.35046
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 500
fps step: 1499 fps step and policy inference: 1431 fps total: 1419 epoch: 500/100000
epoch: 500 mean_rewards: [328.29] mean_lengths: 297.604
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/last_Humanoid_ep_500_rew_328.28705.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 501
fps step: 1491 fps step and policy inference: 1425 fps total: 1412 epoch: 501/100000
epoch: 501 mean_rewards: [327.26] mean_lengths: 297.78906
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.863 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
a_loss 0.850 c_loss 0.000 b_loss 0.000
a_loss 0.843 c_loss 0.000 b_loss 0.000
a_loss 0.833 c_loss 0.000 b_loss 0.000
a_loss 0.821 c_loss 0.000 b_loss 0.000
epoch num: 502
fps step: 1500 fps step and policy inference: 1427 fps total: 1415 epoch: 502/100000
epoch: 502 mean_rewards: [320.] mean_lengths: 295.19092
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.885 c_loss 0.000 b_loss 0.000
a_loss 0.874 c_loss 0.000 b_loss 0.000
a_loss 0.862 c_loss 0.000 b_loss 0.000
epoch num: 503
fps step: 1511 fps step and policy inference: 1449 fps total: 1436 epoch: 503/100000
epoch: 503 mean_rewards: [319.98] mean_lengths: 295.2866
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 504
fps step: 1474 fps step and policy inference: 1411 fps total: 1399 epoch: 504/100000
epoch: 504 mean_rewards: [318.45] mean_lengths: 294.1067
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 505
fps step: 1471 fps step and policy inference: 1408 fps total: 1396 epoch: 505/100000
epoch: 505 mean_rewards: [318.8] mean_lengths: 294.56247
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 506
fps step: 1484 fps step and policy inference: 1417 fps total: 1405 epoch: 506/100000
epoch: 506 mean_rewards: [319.64] mean_lengths: 295.0326
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.855 c_loss 0.000 b_loss 0.000
a_loss 0.849 c_loss 0.000 b_loss 0.000
a_loss 0.843 c_loss 0.000 b_loss 0.000
a_loss 0.836 c_loss 0.000 b_loss 0.000
a_loss 0.826 c_loss 0.000 b_loss 0.000
a_loss 0.813 c_loss 0.000 b_loss 0.000
epoch num: 507
fps step: 1489 fps step and policy inference: 1419 fps total: 1407 epoch: 507/100000
epoch: 507 mean_rewards: [322.7] mean_lengths: 297.42853
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 508
fps step: 1448 fps step and policy inference: 1388 fps total: 1377 epoch: 508/100000
epoch: 508 mean_rewards: [322.5] mean_lengths: 297.55453
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 509
fps step: 1455 fps step and policy inference: 1390 fps total: 1378 epoch: 509/100000
epoch: 509 mean_rewards: [324.51] mean_lengths: 296.58276
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 510
fps step: 1436 fps step and policy inference: 1375 fps total: 1364 epoch: 510/100000
epoch: 510 mean_rewards: [322.7] mean_lengths: 293.93924
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.876 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
a_loss 0.849 c_loss 0.000 b_loss 0.000
a_loss 0.837 c_loss 0.000 b_loss 0.000
epoch num: 511
fps step: 1445 fps step and policy inference: 1380 fps total: 1369 epoch: 511/100000
epoch: 511 mean_rewards: [334.21] mean_lengths: 300.0
saving next best rewards:  [334.21]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.902 c_loss 0.000 b_loss 0.000
a_loss 0.896 c_loss 0.000 b_loss 0.000
a_loss 0.888 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 512
fps step: 1491 fps step and policy inference: 1424 fps total: 1412 epoch: 512/100000
epoch: 512 mean_rewards: [330.16] mean_lengths: 297.65
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 513
fps step: 1459 fps step and policy inference: 1396 fps total: 1385 epoch: 513/100000
epoch: 513 mean_rewards: [329.14] mean_lengths: 297.8096
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.897 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 514
fps step: 1461 fps step and policy inference: 1395 fps total: 1384 epoch: 514/100000
epoch: 514 mean_rewards: [327.8] mean_lengths: 298.05884
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 515
fps step: 1449 fps step and policy inference: 1388 fps total: 1377 epoch: 515/100000
epoch: 515 mean_rewards: [327.07] mean_lengths: 298.19064
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.859 c_loss 0.000 b_loss 0.000
a_loss 0.854 c_loss 0.000 b_loss 0.000
a_loss 0.847 c_loss 0.000 b_loss 0.000
a_loss 0.840 c_loss 0.000 b_loss 0.000
a_loss 0.830 c_loss 0.000 b_loss 0.000
a_loss 0.818 c_loss 0.000 b_loss 0.000
epoch num: 516
fps step: 1460 fps step and policy inference: 1390 fps total: 1378 epoch: 516/100000
epoch: 516 mean_rewards: [328.35] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.907 c_loss 0.000 b_loss 0.000
a_loss 0.902 c_loss 0.000 b_loss 0.000
a_loss 0.894 c_loss 0.000 b_loss 0.000
a_loss 0.887 c_loss 0.000 b_loss 0.000
a_loss 0.876 c_loss 0.000 b_loss 0.000
a_loss 0.864 c_loss 0.000 b_loss 0.000
epoch num: 517
fps step: 1467 fps step and policy inference: 1408 fps total: 1395 epoch: 517/100000
epoch: 517 mean_rewards: [327.69] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 518
fps step: 1431 fps step and policy inference: 1371 fps total: 1360 epoch: 518/100000
epoch: 518 mean_rewards: [328.29] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 519
fps step: 1442 fps step and policy inference: 1378 fps total: 1367 epoch: 519/100000
epoch: 519 mean_rewards: [328.43] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 520
fps step: 1434 fps step and policy inference: 1372 fps total: 1361 epoch: 520/100000
epoch: 520 mean_rewards: [329.85] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.857 c_loss 0.000 b_loss 0.000
a_loss 0.853 c_loss 0.000 b_loss 0.000
a_loss 0.845 c_loss 0.000 b_loss 0.000
a_loss 0.837 c_loss 0.000 b_loss 0.000
a_loss 0.827 c_loss 0.000 b_loss 0.000
a_loss 0.816 c_loss 0.000 b_loss 0.000
epoch num: 521
fps step: 1453 fps step and policy inference: 1383 fps total: 1372 epoch: 521/100000
epoch: 521 mean_rewards: [334.1] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.874 c_loss 0.000 b_loss 0.000
a_loss 0.862 c_loss 0.000 b_loss 0.000
epoch num: 522
fps step: 1454 fps step and policy inference: 1392 fps total: 1381 epoch: 522/100000
epoch: 522 mean_rewards: [333.1] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 523
fps step: 1423 fps step and policy inference: 1362 fps total: 1351 epoch: 523/100000
epoch: 523 mean_rewards: [331.8] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 524
fps step: 1441 fps step and policy inference: 1380 fps total: 1368 epoch: 524/100000
epoch: 524 mean_rewards: [331.38] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.874 c_loss 0.000 b_loss 0.000
a_loss 0.862 c_loss 0.000 b_loss 0.000
epoch num: 525
fps step: 1404 fps step and policy inference: 1346 fps total: 1336 epoch: 525/100000
epoch: 525 mean_rewards: [331.97] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.886 c_loss 0.000 b_loss 0.000
a_loss 0.879 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
a_loss 0.847 c_loss 0.000 b_loss 0.000
epoch num: 526
fps step: 1486 fps step and policy inference: 1415 fps total: 1402 epoch: 526/100000
epoch: 526 mean_rewards: [327.05] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.885 c_loss 0.000 b_loss 0.000
a_loss 0.875 c_loss 0.000 b_loss 0.000
a_loss 0.862 c_loss 0.000 b_loss 0.000
epoch num: 527
fps step: 1477 fps step and policy inference: 1412 fps total: 1400 epoch: 527/100000
epoch: 527 mean_rewards: [327.22] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 528
fps step: 1526 fps step and policy inference: 1455 fps total: 1443 epoch: 528/100000
epoch: 528 mean_rewards: [326.07] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.885 c_loss 0.000 b_loss 0.000
a_loss 0.874 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 529
fps step: 1513 fps step and policy inference: 1448 fps total: 1436 epoch: 529/100000
epoch: 529 mean_rewards: [325.83] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.855 c_loss 0.000 b_loss 0.000
a_loss 0.849 c_loss 0.000 b_loss 0.000
a_loss 0.843 c_loss 0.000 b_loss 0.000
a_loss 0.836 c_loss 0.000 b_loss 0.000
a_loss 0.824 c_loss 0.000 b_loss 0.000
a_loss 0.812 c_loss 0.000 b_loss 0.000
epoch num: 530
fps step: 1461 fps step and policy inference: 1388 fps total: 1376 epoch: 530/100000
epoch: 530 mean_rewards: [326.69] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.907 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.894 c_loss 0.000 b_loss 0.000
a_loss 0.887 c_loss 0.000 b_loss 0.000
a_loss 0.877 c_loss 0.000 b_loss 0.000
a_loss 0.865 c_loss 0.000 b_loss 0.000
epoch num: 531
fps step: 1486 fps step and policy inference: 1427 fps total: 1415 epoch: 531/100000
epoch: 531 mean_rewards: [326.69] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 532
fps step: 1472 fps step and policy inference: 1408 fps total: 1396 epoch: 532/100000
epoch: 532 mean_rewards: [325.96] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 533
fps step: 1456 fps step and policy inference: 1391 fps total: 1379 epoch: 533/100000
epoch: 533 mean_rewards: [325.5] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 534
fps step: 1477 fps step and policy inference: 1413 fps total: 1402 epoch: 534/100000
epoch: 534 mean_rewards: [324.34] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.863 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
a_loss 0.849 c_loss 0.000 b_loss 0.000
a_loss 0.842 c_loss 0.000 b_loss 0.000
a_loss 0.832 c_loss 0.000 b_loss 0.000
a_loss 0.820 c_loss 0.000 b_loss 0.000
epoch num: 535
fps step: 1487 fps step and policy inference: 1415 fps total: 1403 epoch: 535/100000
epoch: 535 mean_rewards: [334.29] mean_lengths: 300.0
saving next best rewards:  [334.29]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.885 c_loss 0.000 b_loss 0.000
a_loss 0.874 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 536
fps step: 1493 fps step and policy inference: 1430 fps total: 1418 epoch: 536/100000
epoch: 536 mean_rewards: [333.72] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 537
fps step: 1488 fps step and policy inference: 1422 fps total: 1410 epoch: 537/100000
epoch: 537 mean_rewards: [335.46] mean_lengths: 300.0
saving next best rewards:  [335.46]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 538
fps step: 1493 fps step and policy inference: 1426 fps total: 1414 epoch: 538/100000
epoch: 538 mean_rewards: [337.76] mean_lengths: 300.0
saving next best rewards:  [337.76]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 539
fps step: 1486 fps step and policy inference: 1421 fps total: 1409 epoch: 539/100000
epoch: 539 mean_rewards: [336.9] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.865 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
a_loss 0.853 c_loss 0.000 b_loss 0.000
a_loss 0.845 c_loss 0.000 b_loss 0.000
a_loss 0.835 c_loss 0.000 b_loss 0.000
a_loss 0.824 c_loss 0.000 b_loss 0.000
epoch num: 540
fps step: 1501 fps step and policy inference: 1428 fps total: 1415 epoch: 540/100000
epoch: 540 mean_rewards: [329.71] mean_lengths: 297.4629
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 541
fps step: 1468 fps step and policy inference: 1405 fps total: 1393 epoch: 541/100000
epoch: 541 mean_rewards: [328.7] mean_lengths: 297.63516
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.856 c_loss 0.000 b_loss 0.000
epoch num: 542
fps step: 1478 fps step and policy inference: 1412 fps total: 1399 epoch: 542/100000
epoch: 542 mean_rewards: [327.26] mean_lengths: 297.86166
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 543
fps step: 1452 fps step and policy inference: 1390 fps total: 1379 epoch: 543/100000
epoch: 543 mean_rewards: [327.14] mean_lengths: 297.98676
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.853 c_loss 0.000 b_loss 0.000
a_loss 0.847 c_loss 0.000 b_loss 0.000
a_loss 0.839 c_loss 0.000 b_loss 0.000
a_loss 0.832 c_loss 0.000 b_loss 0.000
a_loss 0.822 c_loss 0.000 b_loss 0.000
a_loss 0.810 c_loss 0.000 b_loss 0.000
epoch num: 544
fps step: 1451 fps step and policy inference: 1379 fps total: 1368 epoch: 544/100000
epoch: 544 mean_rewards: [329.46] mean_lengths: 297.20462
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.894 c_loss 0.000 b_loss 0.000
a_loss 0.886 c_loss 0.000 b_loss 0.000
a_loss 0.874 c_loss 0.000 b_loss 0.000
a_loss 0.862 c_loss 0.000 b_loss 0.000
epoch num: 545
fps step: 1505 fps step and policy inference: 1445 fps total: 1432 epoch: 545/100000
epoch: 545 mean_rewards: [329.46] mean_lengths: 297.20462
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 546
fps step: 1471 fps step and policy inference: 1406 fps total: 1395 epoch: 546/100000
epoch: 546 mean_rewards: [329.33] mean_lengths: 297.39453
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 547
fps step: 1482 fps step and policy inference: 1413 fps total: 1401 epoch: 547/100000
epoch: 547 mean_rewards: [330.58] mean_lengths: 297.69098
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 548
fps step: 1483 fps step and policy inference: 1418 fps total: 1406 epoch: 548/100000
epoch: 548 mean_rewards: [330.51] mean_lengths: 297.8478
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.865 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
a_loss 0.853 c_loss 0.000 b_loss 0.000
a_loss 0.845 c_loss 0.000 b_loss 0.000
a_loss 0.834 c_loss 0.000 b_loss 0.000
a_loss 0.822 c_loss 0.000 b_loss 0.000
epoch num: 549
fps step: 1495 fps step and policy inference: 1421 fps total: 1409 epoch: 549/100000
epoch: 549 mean_rewards: [333.17] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.886 c_loss 0.000 b_loss 0.000
a_loss 0.875 c_loss 0.000 b_loss 0.000
a_loss 0.864 c_loss 0.000 b_loss 0.000
epoch num: 550
fps step: 1487 fps step and policy inference: 1425 fps total: 1412 epoch: 550/100000
epoch: 550 mean_rewards: [333.3] mean_lengths: 300.0
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/last_Humanoid_ep_550_rew_333.3034.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 551
fps step: 1490 fps step and policy inference: 1424 fps total: 1413 epoch: 551/100000
epoch: 551 mean_rewards: [336.27] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 552
fps step: 1503 fps step and policy inference: 1436 fps total: 1424 epoch: 552/100000
epoch: 552 mean_rewards: [335.78] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.885 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 553
fps step: 1484 fps step and policy inference: 1419 fps total: 1408 epoch: 553/100000
epoch: 553 mean_rewards: [334.28] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.854 c_loss 0.000 b_loss 0.000
a_loss 0.850 c_loss 0.000 b_loss 0.000
a_loss 0.843 c_loss 0.000 b_loss 0.000
a_loss 0.836 c_loss 0.000 b_loss 0.000
a_loss 0.826 c_loss 0.000 b_loss 0.000
a_loss 0.815 c_loss 0.000 b_loss 0.000
epoch num: 554
fps step: 1504 fps step and policy inference: 1431 fps total: 1418 epoch: 554/100000
epoch: 554 mean_rewards: [341.47] mean_lengths: 300.0
saving next best rewards:  [341.47]
=> saving checkpoint 'runs/Humanoid_02-18-16-03/nn/Humanoid.pth'
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.874 c_loss 0.000 b_loss 0.000
a_loss 0.862 c_loss 0.000 b_loss 0.000
epoch num: 555
fps step: 1490 fps step and policy inference: 1426 fps total: 1414 epoch: 555/100000
epoch: 555 mean_rewards: [341.45] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.897 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 556
fps step: 1503 fps step and policy inference: 1433 fps total: 1421 epoch: 556/100000
epoch: 556 mean_rewards: [341.44] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 557
fps step: 1497 fps step and policy inference: 1432 fps total: 1420 epoch: 557/100000
epoch: 557 mean_rewards: [339.96] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.856 c_loss 0.000 b_loss 0.000
a_loss 0.851 c_loss 0.000 b_loss 0.000
a_loss 0.844 c_loss 0.000 b_loss 0.000
a_loss 0.836 c_loss 0.000 b_loss 0.000
a_loss 0.826 c_loss 0.000 b_loss 0.000
a_loss 0.815 c_loss 0.000 b_loss 0.000
epoch num: 558
fps step: 1494 fps step and policy inference: 1420 fps total: 1408 epoch: 558/100000
epoch: 558 mean_rewards: [333.23] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.907 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 559
fps step: 1489 fps step and policy inference: 1429 fps total: 1417 epoch: 559/100000
epoch: 559 mean_rewards: [334.15] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 560
fps step: 1434 fps step and policy inference: 1370 fps total: 1359 epoch: 560/100000
epoch: 560 mean_rewards: [333.9] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 561
fps step: 1431 fps step and policy inference: 1365 fps total: 1354 epoch: 561/100000
epoch: 561 mean_rewards: [334.88] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 562
fps step: 1430 fps step and policy inference: 1364 fps total: 1353 epoch: 562/100000
epoch: 562 mean_rewards: [335.38] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.864 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
a_loss 0.851 c_loss 0.000 b_loss 0.000
a_loss 0.845 c_loss 0.000 b_loss 0.000
a_loss 0.834 c_loss 0.000 b_loss 0.000
a_loss 0.821 c_loss 0.000 b_loss 0.000
epoch num: 563
fps step: 1412 fps step and policy inference: 1341 fps total: 1330 epoch: 563/100000
epoch: 563 mean_rewards: [333.15] mean_lengths: 297.79636
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.886 c_loss 0.000 b_loss 0.000
a_loss 0.876 c_loss 0.000 b_loss 0.000
a_loss 0.864 c_loss 0.000 b_loss 0.000
epoch num: 564
fps step: 1430 fps step and policy inference: 1371 fps total: 1359 epoch: 564/100000
epoch: 564 mean_rewards: [335.27] mean_lengths: 297.86182
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 565
fps step: 1479 fps step and policy inference: 1414 fps total: 1402 epoch: 565/100000
epoch: 565 mean_rewards: [337.87] mean_lengths: 298.04688
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 566
fps step: 1386 fps step and policy inference: 1324 fps total: 1314 epoch: 566/100000
epoch: 566 mean_rewards: [336.42] mean_lengths: 298.1797
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 567
fps step: 1417 fps step and policy inference: 1354 fps total: 1344 epoch: 567/100000
epoch: 567 mean_rewards: [333.81] mean_lengths: 298.3203
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.851 c_loss 0.000 b_loss 0.000
a_loss 0.846 c_loss 0.000 b_loss 0.000
a_loss 0.838 c_loss 0.000 b_loss 0.000
a_loss 0.831 c_loss 0.000 b_loss 0.000
a_loss 0.821 c_loss 0.000 b_loss 0.000
a_loss 0.810 c_loss 0.000 b_loss 0.000
epoch num: 568
fps step: 1484 fps step and policy inference: 1408 fps total: 1398 epoch: 568/100000
epoch: 568 mean_rewards: [328.96] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 569
fps step: 1494 fps step and policy inference: 1431 fps total: 1420 epoch: 569/100000
epoch: 569 mean_rewards: [328.55] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.880 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 570
fps step: 1391 fps step and policy inference: 1328 fps total: 1317 epoch: 570/100000
epoch: 570 mean_rewards: [329.04] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 571
fps step: 1382 fps step and policy inference: 1324 fps total: 1313 epoch: 571/100000
epoch: 571 mean_rewards: [329.35] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.865 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
a_loss 0.851 c_loss 0.000 b_loss 0.000
a_loss 0.844 c_loss 0.000 b_loss 0.000
a_loss 0.833 c_loss 0.000 b_loss 0.000
a_loss 0.821 c_loss 0.000 b_loss 0.000
epoch num: 572
fps step: 1431 fps step and policy inference: 1366 fps total: 1355 epoch: 572/100000
epoch: 572 mean_rewards: [335.59] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 573
fps step: 1503 fps step and policy inference: 1439 fps total: 1427 epoch: 573/100000
epoch: 573 mean_rewards: [335.64] mean_lengths: 297.18582
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 574
fps step: 1476 fps step and policy inference: 1411 fps total: 1400 epoch: 574/100000
epoch: 574 mean_rewards: [335.4] mean_lengths: 297.37695
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.897 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 575
fps step: 1494 fps step and policy inference: 1426 fps total: 1414 epoch: 575/100000
epoch: 575 mean_rewards: [337.69] mean_lengths: 297.6754
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 576
fps step: 1465 fps step and policy inference: 1400 fps total: 1387 epoch: 576/100000
epoch: 576 mean_rewards: [339.74] mean_lengths: 297.83325
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.863 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
a_loss 0.850 c_loss 0.000 b_loss 0.000
a_loss 0.842 c_loss 0.000 b_loss 0.000
a_loss 0.831 c_loss 0.000 b_loss 0.000
a_loss 0.819 c_loss 0.000 b_loss 0.000
epoch num: 577
fps step: 1458 fps step and policy inference: 1387 fps total: 1376 epoch: 577/100000
epoch: 577 mean_rewards: [331.53] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 578
fps step: 1401 fps step and policy inference: 1345 fps total: 1334 epoch: 578/100000
epoch: 578 mean_rewards: [331.37] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.872 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 579
fps step: 1384 fps step and policy inference: 1325 fps total: 1315 epoch: 579/100000
epoch: 579 mean_rewards: [330.52] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.889 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 580
fps step: 1323 fps step and policy inference: 1263 fps total: 1253 epoch: 580/100000
epoch: 580 mean_rewards: [329.5] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.860 c_loss 0.000 b_loss 0.000
epoch num: 581
fps step: 1374 fps step and policy inference: 1314 fps total: 1303 epoch: 581/100000
epoch: 581 mean_rewards: [330.21] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.856 c_loss 0.000 b_loss 0.000
a_loss 0.851 c_loss 0.000 b_loss 0.000
a_loss 0.843 c_loss 0.000 b_loss 0.000
a_loss 0.836 c_loss 0.000 b_loss 0.000
a_loss 0.825 c_loss 0.000 b_loss 0.000
a_loss 0.814 c_loss 0.000 b_loss 0.000
epoch num: 582
fps step: 1381 fps step and policy inference: 1314 fps total: 1303 epoch: 582/100000
epoch: 582 mean_rewards: [329.81] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.906 c_loss 0.000 b_loss 0.000
a_loss 0.900 c_loss 0.000 b_loss 0.000
a_loss 0.892 c_loss 0.000 b_loss 0.000
a_loss 0.884 c_loss 0.000 b_loss 0.000
a_loss 0.873 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 583
fps step: 1352 fps step and policy inference: 1291 fps total: 1281 epoch: 583/100000
epoch: 583 mean_rewards: [329.12] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.869 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 584
fps step: 1335 fps step and policy inference: 1274 fps total: 1264 epoch: 584/100000
epoch: 584 mean_rewards: [327.95] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 585
fps step: 1353 fps step and policy inference: 1296 fps total: 1286 epoch: 585/100000
epoch: 585 mean_rewards: [327.8] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.877 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
a_loss 0.848 c_loss 0.000 b_loss 0.000
a_loss 0.836 c_loss 0.000 b_loss 0.000
epoch num: 586
fps step: 1407 fps step and policy inference: 1344 fps total: 1333 epoch: 586/100000
epoch: 586 mean_rewards: [339.77] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.903 c_loss 0.000 b_loss 0.000
a_loss 0.897 c_loss 0.000 b_loss 0.000
a_loss 0.888 c_loss 0.000 b_loss 0.000
a_loss 0.879 c_loss 0.000 b_loss 0.000
a_loss 0.868 c_loss 0.000 b_loss 0.000
a_loss 0.855 c_loss 0.000 b_loss 0.000
epoch num: 587
fps step: 1373 fps step and policy inference: 1311 fps total: 1301 epoch: 587/100000
epoch: 587 mean_rewards: [335.13] mean_lengths: 297.61682
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.899 c_loss 0.000 b_loss 0.000
a_loss 0.891 c_loss 0.000 b_loss 0.000
a_loss 0.882 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.859 c_loss 0.000 b_loss 0.000
epoch num: 588
fps step: 1397 fps step and policy inference: 1337 fps total: 1326 epoch: 588/100000
epoch: 588 mean_rewards: [336.08] mean_lengths: 297.77863
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.904 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.881 c_loss 0.000 b_loss 0.000
a_loss 0.870 c_loss 0.000 b_loss 0.000
a_loss 0.857 c_loss 0.000 b_loss 0.000
epoch num: 589
fps step: 1353 fps step and policy inference: 1294 fps total: 1284 epoch: 589/100000
epoch: 589 mean_rewards: [333.7] mean_lengths: 298.03137
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.905 c_loss 0.000 b_loss 0.000
a_loss 0.898 c_loss 0.000 b_loss 0.000
a_loss 0.890 c_loss 0.000 b_loss 0.000
a_loss 0.883 c_loss 0.000 b_loss 0.000
a_loss 0.871 c_loss 0.000 b_loss 0.000
a_loss 0.858 c_loss 0.000 b_loss 0.000
epoch num: 590
fps step: 1393 fps step and policy inference: 1334 fps total: 1323 epoch: 590/100000
epoch: 590 mean_rewards: [333.56] mean_lengths: 298.14648
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.860 c_loss 0.000 b_loss 0.000
a_loss 0.854 c_loss 0.000 b_loss 0.000
a_loss 0.847 c_loss 0.000 b_loss 0.000
a_loss 0.838 c_loss 0.000 b_loss 0.000
a_loss 0.827 c_loss 0.000 b_loss 0.000
a_loss 0.815 c_loss 0.000 b_loss 0.000
epoch num: 591
fps step: 1437 fps step and policy inference: 1369 fps total: 1357 epoch: 591/100000
epoch: 591 mean_rewards: [331.6] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
a_loss 0.907 c_loss 0.000 b_loss 0.000
a_loss 0.901 c_loss 0.000 b_loss 0.000
a_loss 0.893 c_loss 0.000 b_loss 0.000
a_loss 0.885 c_loss 0.000 b_loss 0.000
a_loss 0.874 c_loss 0.000 b_loss 0.000
a_loss 0.861 c_loss 0.000 b_loss 0.000
epoch num: 592
fps step: 1518 fps step and policy inference: 1456 fps total: 1443 epoch: 592/100000
epoch: 592 mean_rewards: [331.92] mean_lengths: 300.0
motion end, start again:  256
motion end, start again:  256
motion end, start again:  256
